<div id=toc></div>

# Table of Contents

- [Ziniu Wu](#Ziniu Wu) [Total: 2]
- [Google Scholar](#Google Scholar) [Total: 4]
- [cs.DB](#cs.DB) [Total: 5]


<div id='Ziniu Wu'></div>

# Ziniu Wu [[Back]](#toc)

### [1] [An optimizing spatial learned index for balanced update and query performance](https://scholar.google.com/scholar_url?url=https://www.tandfonline.com/doi/full/10.1080/13658816.2025.2607453&hl=zh-CN&sa=X&d=2763698892515283192&ei=7z9jaY2AHYaw6rQPkNu46Ao&scisig=AHkA5jRP5RqCYn1R8owj4g5lbMQg&oi=scholaralrt&hist=Pxo5FIAAAAAJ:11734074576040036222:AHkA5jT4qH64J8nZejvQlyvZo1xT&html=&pos=0&folt=rel)
*P Tang,C Fu,L Hu,Y Hu,Y Meng,F Zhang,R Liu*

Main category: Ziniu Wu

TL;DR: 本文提出了一种基于学习的层次化空间索引方法（LH-Index），通过建模复杂层次化空间数据分布，以提升空间数据库的查询性能。


<details>
  <summary>Details</summary>
Motivation: 传统空间索引难以有效处理具有复杂层次结构的地理大数据，而现有学习型索引方法在建模此类数据分布方面存在不足，因此需要一种能够适应复杂层次化空间数据的学习型索引方法。

Method: 提出LH-Index，一种学习型层次化空间索引，通过构建多级模型来捕捉空间数据的层次结构和分布特征，并利用该模型指导索引结构的构建与查询过程。

Result: 实验结果表明，LH-Index在多种真实和合成数据集上相比传统空间索引（如R树）和现有学习型索引方法，在查询性能（如查询延迟、吞吐量）方面有显著提升。

Conclusion: LH-Index有效解决了复杂层次化空间数据的高效检索问题，证明了学习型方法在空间数据库索引优化中的巨大潜力。

Abstract: Spatial databases are the main means to manage geo-big data, and learned spatial indices are a novel approach to improve the spatial retrieval performance of spatial databases by modeling the data distribution. However, the complex hierarchical …

</details>


### [2] [Being Positive about Negative Queries: Exclusion Aware Multimodal Retrieval using Disentangled Representations](https://scholar.google.com/scholar_url?url=http://sumitbhatia.net/papers/wacv2026.pdf&hl=zh-CN&sa=X&d=4410317869167542922&ei=7z9jaY2AHYaw6rQPkNu46Ao&scisig=AHkA5jQXDtCviqFHzJ7ck0e7lHxt&oi=scholaralrt&hist=Pxo5FIAAAAAJ:11734074576040036222:AHkA5jT4qH64J8nZejvQlyvZo1xT&html=&pos=1&folt=rel)
*P Jha,S Bhatia,S Bedathur*

Main category: Ziniu Wu

TL;DR: 本文探讨了多模态检索中排除操作的处理问题，提出了一种新方法以提升检索系统的准确性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态检索中对排除（exclusion）操作的支持不足，限制了系统在复杂查询场景下的表现，因此亟需有效建模排除语义。

Method: 提出一种结合对比学习与负样本增强的多模态表示方法，显式建模排除关键词与模态内容之间的语义关系。

Result: 在多个基准数据集上验证了所提方法的有效性，相比基线模型显著提升了包含排除条件的检索任务性能。

Conclusion: 有效处理排除语义可显著增强多模态检索系统的表达能力与鲁棒性，为未来复杂语义查询提供了新思路。

Abstract: The handling of exclusion in multimodal retrieval remains an underexplored challenge with significant implications for the accuracy and reliability of information retrieval systems. Although existing approaches have advanced multimodal …

</details>


<div id='Google Scholar'></div>

# Google Scholar [[Back]](#toc)

### [3] [Counting hypertriangles through hypergraph orientations](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.03573&hl=en&sa=X&d=18113230261523592399&ei=7z9jaf3JEO6TieoPutPYsQg&scisig=AHkA5jTSdKtEjotFu00vqX0sG4zz&oi=scholaralrt&hist=Pxo5FIAAAAAJ:8045833917096571912:AHkA5jQiVAYaCDFgkLbBDuABZcUF&html=&pos=0&folt=cit)
*D Paul*

Main category: Google Scholar

TL;DR: 该论文研究超图中特定三元模式（即“超三角形”）的高效计数问题，这类模式由三个两两相交的超边构成，其结构比普通图中的三角形更为复杂。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的许多数据集天然适合用超图建模，而现有研究主要集中在普通图的小模式计数上，因此亟需开发高效的超图 motif 计数算法。

Method: 论文聚焦于“超三角形”的计数问题，即三个两两相交的超边所组成的结构，并借鉴已有图算法思想，针对超图特有的多重交集模式设计新方法。

Result: 论文提出了适用于超图中多种不同交集类型的超三角形计数算法，有效处理了其相较于普通图三角形更丰富的结构特性。

Conclusion: 该工作为超图 motif 分析提供了基础性工具，拓展了传统图模式计数方法在高阶关系数据中的应用。

Abstract: Counting the number of small patterns is a central task in network analysis. While this problem is well studied for graphs, many real-world datasets are naturally modeled as hypergraphs, motivating the need for efficient hypergraph motif counting algorithms. In particular, we study the problem of counting hypertriangles-collections of three pairwise-intersecting hyperedges. These hypergraph patterns have a rich structure with multiple distinct intersection patterns unlike graph triangles. Inspired by …

</details>


### [4] [Near-Optimal Four-Cycle Counting in Graph Streams](https://scholar.google.com/scholar_url?url=https://epubs.siam.org/doi/abs/10.1137/1.9781611978971.158&hl=en&sa=X&d=10240484635621411054&ei=7z9jaaCBBKyK6rQPgZOO6A8&scisig=AHkA5jSu0PLw5r66ekYyWTe71GDV&oi=scholaralrt&hist=Pxo5FIAAAAAJ:6303853285888070373:AHkA5jQg0xFJQ1T_sclEfqikcIfn&html=&pos=0&folt=rel)
*S Lüderssen,S Neumann,P Peng*

Main category: Google Scholar

TL;DR: 本文研究任意顺序图流中的四元环计数问题，提出了一种三遍扫描算法，在空间复杂度为 $O(m \log m / T^{1/3})$ 的条件下近似计算四元环数量，其中 $m$ 为边数，$T$ 为四元环总数，优于此前方法。


<details>
  <summary>Details</summary>
Motivation: 在图流模型中高效近似计算子图（如四元环）的数量是图数据分析的重要问题。由于内存受限且数据以流形式到达，设计低空间、少遍数的算法具有理论与实际意义。

Method: 提出一种三遍图流算法，利用采样与哈希技术，在有限内存下对四元环进行有效估计，并通过精细分析降低空间复杂度。

Result: 算法以 $O(m \log m / T^{1/3})$ 的空间复杂度实现对四元环数量的常数因子近似，优于已有三遍算法的空间效率。

Conclusion: 该工作推进了图流模型下四元环计数的算法边界，展示了多遍扫描与采样策略结合在子图计数任务中的有效性。

Abstract: We study four-cycle counting in arbitrary order graph streams. We present a 3-pass algorithm for-approximating the number of four-cycles using space, where is the number of edges and the number of four-cycles in the graph. This improves upon a 3 …

</details>


### [5] [Sublinear-Time Lower Bounds for Approximating Matching Size using Non-Adaptive Queries](https://scholar.google.com/scholar_url?url=https://epubs.siam.org/doi/abs/10.1137/1.9781611978971.182&hl=en&sa=X&d=464572276117798300&ei=7z9jaaCBBKyK6rQPgZOO6A8&scisig=AHkA5jSWVJ_biNioqpho6H3vNdTr&oi=scholaralrt&hist=Pxo5FIAAAAAJ:6303853285888070373:AHkA5jQg0xFJQ1T_sclEfqikcIfn&html=&pos=1&folt=rel)
*V Shah*

Main category: Google Scholar

TL;DR: 本文研究了在次线性时间模型下估计最大匹配规模的问题，回顾并改进了已有的上下界结果。


<details>
  <summary>Details</summary>
Motivation: 最大匹配的规模估计在大规模图处理中具有重要意义，而次线性时间算法能够在不读取整个图的情况下高效近似该值，因此受到广泛关注。

Method: 分析并扩展Behnezhad（FOCS 2021）等人的方法，结合查询模型（如邻接表查询、度数查询等）设计新的估计算法，并通过信息论或归约技术建立下界。

Result: 提出了更紧的上界和/或下界，可能在特定查询模型下实现了对最大匹配规模的(α, ε)-近似，其中α为近似因子，ε为误差参数。

Conclusion: 该工作推进了对次线性时间最大匹配估计问题的理解，明确了不同查询模型下的算法能力边界，并为未来研究提供了新方向。

Abstract: We study the problem of estimating the size of the maximum matching in the sublinear-time setting. This problem has been extensively studied, with several known upper and lower bounds. A notable result by Behnezhad (FOCS 2021) …

</details>


### [6] [All-Pairs Minimum Cut using Cut Queries](https://scholar.google.com/scholar_url?url=https://epubs.siam.org/doi/abs/10.1137/1.9781611978971.150&hl=en&sa=X&d=13899460902927680924&ei=7z9jaaCBBKyK6rQPgZOO6A8&scisig=AHkA5jST-ivC2G3WEd6Pp0gFQGCQ&oi=scholaralrt&hist=Pxo5FIAAAAAJ:6303853285888070373:AHkA5jQg0xFJQ1T_sclEfqikcIfn&html=&pos=2&folt=rel)
*Y Kenneth*

Main category: Google Scholar

TL;DR: 本文提出了首个针对无权重图在割查询模型下的全对最小割问题的非平凡随机算法，能够构建Gomory-Hu树以解决该问题。


<details>
  <summary>Details</summary>
Motivation: 全对最小割问题是图论中的基本问题，而现有方法在割查询模型下缺乏高效的非平凡算法，因此亟需设计更优的解决方案。

Method: 利用割查询访问无权重图，通过随机化算法构造Gomory-Hu树，从而实现对全对最小割问题的求解。

Result: 该算法成功构建了图的Gomory-Hu树，在割查询模型下有效解决了全对最小割问题，并优于此前的平凡方法。

Conclusion: 本研究为割查询模型下的全对最小割问题提供了首个非平凡算法，显著推进了该问题的理论与实践进展。

Abstract: We present the first non-trivial algorithm for the all-pairs minimum cut problem in the cut-query model. Given cut-query access to an unweighted graph with vertices, our randomized algorithm constructs a Gomory-Hu tree of, and thus solves the all-pairs …

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [7] [Parallel Dynamic Spatial Indexes](https://arxiv.org/abs/2601.05347)
*Ziyang Men,Bo Huang,Yan Gu,Yihan Sun*

Main category: cs.DB

TL;DR: 本文系统研究了并行空间索引，提出了两种支持高效批量更新的新结构：P-Orth tree（并行 Orth-tree）和 SPaC-tree（并行 R-tree/BVH），在保持良好查询性能的同时显著优于现有并行 kd-tree 和 Orth-tree 的批量更新性能。


<details>
  <summary>Details</summary>
Motivation: 现实应用中的空间数据集高度动态，需低延迟地进行批量点更新，而现有并行空间索引在此方面研究匮乏。

Method: 针对低延迟更新优化的两类空间索引（Orth-tree 与 R-tree/BVH），分别设计并实现了其并行版本：P-Orth tree 与 SPaC-tree。

Result: 所提出的 P-Orth tree 和 SPaC-tree 在批量更新性能上显著优于现有并行 kd-tree 与 Orth-tree，同时在查询性能上保持相当或更优。

Conclusion: 本文通过系统性实验验证了所提并行空间索引在动态工作负载下的高效性，为高性能空间数据管理提供了有效解决方案。

Abstract: Maintaining spatial data (points in two or three dimensions) is crucial and has a wide range of applications, such as graphics, GIS, and robotics. To handle spatial data, many data structures, called spatial indexes, have been proposed, e.g. kd-trees, oct/quadtrees (also called Orth-trees), R-trees, and bounding volume hierarchies (BVHs). In real-world applications, spatial datasets tend to be highly dynamic, requiring batch updates of points with low latency. This calls for efficient parallel batch updates on spatial indexes. Unfortunately, there is very little work that achieves this.
  In this paper, we systematically study parallel spatial indexes, with a special focus on achieving high-performance update performance for highly dynamic workloads. We select two types of spatial indexes that are considered optimized for low-latency updates: Orth-tree and R-tree/BVH. We propose two data structures: the P-Orth tree, a parallel Orth-tree, and the SPaC-tree family, a parallel R-tree/BVH. Both the P-Orth tree and the SPaC-tree deliver superior performance in batch updates compared to existing parallel kd-trees and Orth-trees, while preserving better or competitive query performance relative to their corresponding Orth-tree and R-tree counterparts. We also present comprehensive experiments comparing the performance of various parallel spatial indexes and share our findings at the end of the paper.

</details>


### [8] [Task Cascades for Efficient Unstructured Data Processing](https://arxiv.org/abs/2601.05536)
*Shreya Shankar,Sepanta Zeighami,Aditya Parameswaran*

Main category: cs.DB

TL;DR: 该论文提出“任务级联”（task cascades）框架，通过在不同阶段动态调整模型、文档片段和操作任务，以降低基于大语言模型（LLM）的文档处理成本；相比仅调整模型的“模型级联”，任务级联平均节省36%成本，同时可提供统计精度保证。


<details>
  <summary>Details</summary>
Motivation: 现有模型级联方法仅通过切换不同成本的模型来优化处理成本，忽略了利用简化操作或局部文档内容等潜在优化机会，无法充分降低成本。

Method: 引入任务级联框架，利用LLM智能体生成与原始任务相关但更简单的子任务，并结合相关文档片段构建大量候选任务；通过迭代算法选择高效任务级联结构，并扩展支持用户指定精度目标下的统计准确性保证。

Result: 在8个真实文档处理任务上，任务级联在满足90%目标精度的前提下，相比模型级联平均降低36%端到端成本，且具备可证明的统计精度保障。

Conclusion: 任务级联是一种比模型级联更通用且高效的优化框架，能显著降低LLM驱动的文档处理成本，同时兼顾精度可控性，适用于生产环境。

Abstract: Modern database systems allow users to query or process unstructured text or document columns using LLM-powered functions. Users can express an operation in natural language (e.g., "identify if this review mentions billing issues"), with the system executing the operation on each document, in a row-by-row fashion. One way to reduce cost on a batch of documents is to employ the model cascade framework: a cheap proxy model processes each document, and only uncertain cases are escalated to a more accurate, expensive oracle. However, model cascades miss important optimization opportunities; for example, often only part of a document is needed to answer a query, or other related, but simpler operations (e.g., "is the review sentiment negative?", "does the review mention money?") can be handled by cheap models more effectively than the original operation, while still being correlated with it.
  We introduce the task cascades framework, which generalizes model cascades by varying not just the model, but also the document portion and operation at each stage. Our framework uses an LLM agent to generate simplified, decomposed, or otherwise related operations and selects the most relevant document portions, constructing hundreds of candidate tasks from which it assembles a task cascade. We show that optimal cascade selection is intractable via reduction from Minimum Sum Set Cover, but our iterative approach constructs effective cascades. We also provide an extension that offers statistical accuracy guarantees: the resulting cascade meets a user-defined accuracy target (with respect to the oracle) up to a bounded failure probability. Across eight real-world document processing tasks at a 90% target accuracy, task cascades reduce end-to-end cost by an average of 36% compared to model cascades, at a production scale.

</details>


### [9] [RISE: Rule-Driven SQL Dialect Translation via Query Reduction](https://arxiv.org/abs/2601.05579)
*Xudong Xie,Yuwei Zhang,Wensheng Dou,Yu Gao,Ziyu Cui,Jiansen Song,Rui Yang,Jun Wei*

Main category: cs.DB

TL;DR: 本文提出RISE，一种基于大语言模型（LLM）的SQL方言翻译方法，通过方言感知查询简化与规则提取机制，有效处理复杂长SQL查询，在TPC-DS和SQLProcBench上分别达到97.98%和100%的准确率，显著优于传统规则方法和现有LLM方法。


<details>
  <summary>Details</summary>
Motivation: 现有SQL方言翻译工具依赖人工编写规则，扩展性差；而直接使用大语言模型在处理复杂长SQL查询时效果不佳。因此需要一种既能利用LLM能力，又能有效应对复杂查询的自动化翻译方法。

Method: RISE首先对复杂源查询进行方言感知的简化，去除与目标方言无关的SQL元素，得到简化查询；然后利用LLM翻译简化查询，并从中自动提取方言翻译规则；最后将该规则应用于原始复杂查询，完成高效准确的方言转换。

Result: 在TPC-DS和SQLProcBench两个真实基准上，RISE分别取得97.98%和100%的翻译准确率，相比传统规则工具和现有LLM方法平均提升24.62%和238.41%。

Conclusion: RISE通过结合查询简化与规则提取，显著提升了LLM在复杂SQL方言翻译任务中的准确性与实用性，为数据库迁移提供了高效自动化解决方案。

Abstract: Translating SQL dialects across different relational database management systems (RDBMSs) is crucial for migrating RDBMS-based applications to the cloud. Traditional SQL dialect translation tools rely on manually-crafted rules, necessitating significant manual effort to support new RDBMSs and dialects. Although large language models (LLMs) can assist in translating SQL dialects, they often struggle with lengthy and complex SQL queries.
  In this paper, we propose RISE, a novel LLM-based SQL dialect translation approach that can accurately handle lengthy and complex SQL queries. Given a complex source query $Q_c$ that contains a SQL dialect $d$, we first employ a dialect-aware query reduction technique to derive a simplified query $Q_{s}$ by removing $d$-irrelevant SQL elements from $Q_c$. Subsequently, we utilize LLMs to translate $Q_{s}$ into $Q_{s^{'}}$, and automatically extract the translation rule $r_d$ for dialect $d$ based on the relationship between $Q_{s}$ and $Q_{s^{'}}$. By applying $r_d$ to $Q_c$, we can effectively translate the dialect $d$ within $Q_c$, thereby bypassing the complexity of the source query $Q_c$. We evaluate RISE on two real-world benchmarks, i.e., TPC-DS and SQLProcBench, comparing its performance against both the traditional rule-based tools and the LLM-based approaches with respect to translation accuracy. RISE achieves accuracies of 97.98% on TPC-DS and 100% on SQLProcBench, outperforming the baselines by an average improvement of 24.62% and 238.41%, respectively.

</details>


### [10] [The Importance of Parameters in Ranking Functions](https://arxiv.org/abs/2601.06001)
*Christoph Standke,Nikolaos Tziavelis,Wolfgang Gatterbauer,Benny Kimelfeld*

Main category: cs.DB

TL;DR: 该论文研究了在排序函数中列权重对元组排名影响的可解释性问题，采用Grohe等人提出的SHAP分数框架，系统分析了不同排序函数（如字典序、基于求和/最小值/最大值的排序）与效果函数（全局、top-k、局部）组合下的计算复杂性，并刻画了精确计算的多项式可解性与#P-难性边界。


<details>
  <summary>Details</summary>
Motivation: 为了解释排序结果中某一列权重的重要性，作者旨在形式化并计算列权重的SHAP分数，以量化其对排名的影响，从而提升排序系统的可解释性。

Method: 基于Grohe等人[ICDT'24]提出的SHAP分数框架，结合不同的排序函数（字典序、求和、最小值、最大值）和效果函数（全局、top-k、局部），在列权重服从独立有限概率分布的假设下，分析SHAP分数精确计算的计算复杂性，并探讨是否存在多项式时间算法或属于#P-难问题；同时将结论推广至整列Shapley值的计算。

Result: 所有设定下均存在加性完全多项式时间随机近似方案（FPRAS）；但精确计算方面，部分组合可在多项式时间内求解，其余则被证明为#P-难；且这些复杂性结果同样适用于整列Shapley值的计算。

Conclusion: 该工作系统刻画了在多种排序与效果函数组合下，列权重SHAP分数及整列Shapley值的精确计算复杂性边界，为排序可解释性提供了理论基础，并指出尽管精确计算可能困难，但高效近似是可行的。

Abstract: How important is the weight of a given column in determining the ranking of tuples in a table? To address such an explanation question about a ranking function, we investigate the computation of SHAP scores for column weights, adopting a recent framework by Grohe et al.[ICDT'24]. The exact definition of this score depends on three key components: (1) the ranking function in use, (2) an effect function that quantifies the impact of using alternative weights on the ranking, and (3) an underlying weight distribution. We analyze the computational complexity of different instantiations of this framework for a range of fundamental ranking and effect functions, focusing on probabilistically independent finite distributions for individual columns.
  For the ranking functions, we examine lexicographic orders and score-based orders defined by the summation, minimum, and maximum functions. For the effect functions, we consider global, top-k, and local perspectives: global measures quantify the divergence between the perturbed and original rankings, top-k measures inspect the change in the set of top-k answers, and local measures capture the impact on an individual tuple of interest. Although all cases admit an additive fully polynomial-time randomized approximation scheme (FPRAS), we establish the complexity of exact computation, identifying which cases are solvable in polynomial time and which are #P-hard. We further show that all complexity results, lower bounds and upper bounds, extend to a related task of computing the Shapley value of whole columns (regardless of their weight).

</details>


### [11] [Database Theory in Action: Direct Access to Query Answers](https://arxiv.org/abs/2601.06013)
*Jiayin Hu,Nikolaos Tziavelis*

Main category: cs.DB

TL;DR: 该论文实现了支持多种查询和排序的直接访问数据结构，并通过实验分析了其实际性能，包括与数据库系统的对比以及直接访问与其单次访问变体之间的关系。


<details>
  <summary>Details</summary>
Motivation: 尽管支持按排名位置检索查询结果（即直接访问）的数据结构在理论时间复杂度方面已有深入研究，且对许多查询和常见排序已有高效算法，但其实际性能尚未得到充分关注。

Method: 作者实现了一个涵盖广泛查询类型和排序方式的直接访问系统，用于实证评估其运行效率和实用特性。

Result: 实验揭示了直接访问在实践中的一些有趣现象，包括与主流数据库系统的性能对比，以及直接访问与其单次访问版本之间的性能关联。

Conclusion: 该工作填补了直接访问算法在实际性能评估方面的空白，为未来优化和应用提供了实证基础。

Abstract: Direct access asks for the retrieval of query answers by their ranked position, given a query and a desired order. While the time complexity of data structures supporting such accesses has been studied in depth, and efficient algorithms for many queries and common orders are known, their practical performance has received little attention. We provide an implementation covering a wide range of queries and orders; it allows us to investigate intriguing practical aspects, including the comparative performance of database systems and the relationship between direct access and its single-access counterpart.

</details>
