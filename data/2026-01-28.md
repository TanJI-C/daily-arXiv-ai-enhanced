<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 4]
- [Ziniu Wu](#Ziniu Wu) [Total: 1]
- [learned "cost model"](#learned "cost model") [Total: 7]
- ["query optimization"](#"query optimization") [Total: 7]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Accelerating Large-Scale Cheminformatics Using a Byte-Offset Indexing Architecture for Terabyte-Scale Data Integration](https://arxiv.org/abs/2601.18921)
*Malikussaid,Septian Caesar Floresko,Sutiyo*

Main category: cs.DB

TL;DR: 该论文通过整合PubChem、ChEMBL和eMolecules三大化学数据库，利用字节偏移索引技术将原本需100天的暴力匹配算法优化至3.2小时完成，实现了740倍性能提升，并在处理1.76亿化合物时发现InChIKey哈希冲突问题，改用完整InChI字符串确保数据唯一性，最终构建了包含435,413个验证化合物的高质量数据集。


<details>
  <summary>Details</summary>
Motivation: 大规模化学数据库的整合是现代化学信息学研究中的关键瓶颈，尤其对于依赖高质量、多源验证数据集的机器学习应用。现有方法在处理上亿级化合物时面临计算效率低下和分子标识符哈希冲突等问题，亟需可扩展且保证数据完整性的整合策略。

Method: 作者采用字节偏移索引（byte-offset indexing）架构替代传统的暴力搜索算法，将算法复杂度从O(N×M)降至O(N+M)；同时，在发现InChIKey存在哈希碰撞后，重构数据管道，使用无冲突的完整InChI字符串作为分子唯一标识符，以确保数据完整性。

Result: 系统成功将整合时间从预估的100天缩短至3.2小时（740倍加速），在1.76亿条记录中识别出InChIKey哈希冲突，并基于完整InChI构建了包含435,413个经多源验证的化合物的高质量数据集；同时提供了存储开销与科学严谨性之间的量化权衡分析。

Conclusion: 该研究展示了字节偏移索引在超大规模化学数据整合中的有效性，并揭示了哈希型分子标识符在亿级数据下的局限性；所提出的方法具有通用性，可推广至其他对唯一性要求超出哈希能力的大规模科学数据集成场景。

Abstract: The integration of large-scale chemical databases represents a critical bottleneck in modern cheminformatics research, particularly for machine learning applications requiring high-quality, multi-source validated datasets. This paper presents a case study of integrating three major public chemical repositories: PubChem (176 million compounds), ChEMBL, and eMolecules, to construct a curated dataset for molecular property prediction. We investigate whether byte-offset indexing can practically overcome brute-force scalability limits while preserving data integrity at hundred-million scale. Our results document the progression from an intractable brute-force search algorithm with projected 100-day runtime to a byte-offset indexing architecture achieving 3.2-hour completion-a 740-fold performance improvement through algorithmic complexity reduction from O(NxM) to O(N+M). Systematic validation of 176 million database entries revealed hash collisions in InChIKey molecular identifiers, necessitating pipeline reconstruction using collision-free full InChI strings. We present performance benchmarks, quantify trade-offs between storage overhead and scientific rigor, and compare our approach with alternative large-scale integration strategies. The resulting system successfully extracted 435,413 validated compounds and demonstrates generalizable principles for large-scale scientific data integration where uniqueness constraints exceed hash-based identifier capabilities.

</details>


### [2] [Educational Database Prototype: the Simplest of All](https://arxiv.org/abs/2601.19165)
*Yi Lyu,Yiyin Shen,Takashi Matsuzawa*

Main category: cs.DB

TL;DR: 本文介绍了EduDB——一个用于教学的简化数据库原型，旨在为本科生提供对数据库系统内部设计的清晰、简洁且全面的理解，并支持基于该原型的一系列综合性课程项目。


<details>
  <summary>Details</summary>
Motivation: 当前威斯康星大学麦迪逊分校（UW-Madison）的本科数据库课程（CS564）要求学生实现数据库架构中的特定模块（如B+树），但学生常因处理大量边界情况而耗费过多精力，难以获得对数据库整体设计的深入理解。

Method: 开发了一个名为EduDB的轻量级教育用数据库原型，提供清晰、简洁的系统结构，并围绕其设计一系列集成式课程项目，使学生能在统一平台上实践学期中所学的各种优化技术。

Result: EduDB为学生提供了一个易于理解且可扩展的教学平台，使其能专注于数据库核心机制与优化策略，而非陷入底层细节和边缘情况的调试中。

Conclusion: EduDB有效提升了数据库课程的教学效果，帮助学生更全面地掌握数据库系统的内部工作原理，并为后续的优化实践提供了良好基础。

Abstract: Database Management System (DBMS) is designed to help store and process large collections of data, and is incredibly flexible to perform various kinds of optimizations as long as it achieves serializability with a high-level interface available. The current undergraduate level DBMS course in UW-Madison (i.e., CS564) involves implementing specific modules of DB architecture, including B+ tree, but students may end up spending numerous amounts of effort on corner cases and not gaining a more comprehensive understanding of the internal design. Thus, we present EduDB, a simple database prototype for educational purposes that provides students a clean, concise, and comprehensive overview of the database system. We also attempt to develop an integrative series of course projects based on EduDB, which offers a platform for students to perform any optimization learned during the semester.

</details>


### [3] [Create Benchmarks for Data Lakes](https://arxiv.org/abs/2601.19176)
*Yi Lyu,Pei-Chieh Lo,Natan Lidukhover*

Main category: cs.DB

TL;DR: 本文提出了一种面向数据湖的新基准测试框架，以全面评估不同数据湖系统在多种数据类型和工作负载下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要针对传统数据仓库和结构化SQL工作负载，无法充分反映数据湖中常见的异构数据类型和多样化访问模式（如相似性搜索），因此亟需一个专门针对数据湖的标准化、综合性基准。

Method: 设计并实现了一个可扩展、可复现的数据湖基准测试框架，涵盖数据检索、聚合、查询和相似性搜索等多种工作负载；在不同规模因子下测量查询执行时间、元数据生成时间和元数据大小等关键指标，并在CloudLab平台上对商业和开源数据湖系统进行实验评估。

Result: 该基准成功应用于多个数据湖平台的比较，展示了其在真实和多样化场景下评估系统性能的能力，尤其突出了对相似性搜索等非传统操作的支持。

Conclusion: 所提出的基准填补了数据湖系统评估的空白，为未来数据湖技术的开发与优化提供了客观、可复现的评估工具。

Abstract: Data lakes have emerged as a flexible and scalable solution for storing and analyzing large volumes of heterogeneous data, including structured, semi-structured, and unstructured formats. Despite their growing adoption in both industry and academia, there is a lack of standardized and comprehensive benchmarks for evaluating the performance of data lake systems. Existing benchmarks primarily target traditional data warehouses and focus on structured SQL workloads, making them insufficient for capturing the diverse workloads and access patterns typical of data lakes.
  In this work, we propose a new benchmarking framework for data lakes that aims to provide an objective and comparative evaluation of different data lake implementations. Our benchmark covers multiple data types and workload models, including data retrieval, aggregation, querying, and similarity search, which is a common yet underexplored operation in existing benchmarks. We measure key performance metrics such as query execution time, metadata generation time, and metadata size across different scale factors. The benchmark is designed to be extensible and reproducible, enabling users to generate datasets and evaluate data lake systems under realistic and diverse scenarios. We conduct our experiments on CloudLab and demonstrate how the proposed benchmark can be used to compare both commercial and open-source data lake platforms.

</details>


### [4] [Topology-Aware Subset Repair via Entropy-Guided Density and Graph Decomposition](https://arxiv.org/abs/2601.19671)
*Guoqi Zhao,Xixian Han,Xiaolong Wan*

Main category: cs.DB

TL;DR: 本文提出一种基于拓扑感知的近似子集修复框架，通过结合密度与冲突惩罚模型，有效提升数据修复的准确性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于密度的子集修复方法存在脏数据簇引起的密度偏差、计算开销高及属性权重统一等问题，导致修复结果不理想。

Method: 该框架包含三部分：1）两层冲突检测策略，结合属性倒排索引与CFD规则分组高效识别冲突；2）提出EntroCFDensity密度度量，融合信息熵与CFD权重动态调整属性重要性；3）定义冲突度以补充局部密度，构建基于变异系数的动态加权拓扑自适应惩罚机制，并将冲突图分解为独立子图以实现局部修复。在此基础上开发了启发式算法PPIS和带理论保证的混合整数规划算法MICO。

Result: 实验表明，所提方法在修复准确率和鲁棒性方面优于现有方法，同时能有效保留高质量数据。

Conclusion: 通过引入拓扑感知机制与动态加权策略，该框架有效缓解了传统密度方法的偏差问题，为子集修复提供了更可靠、可扩展的解决方案。

Abstract: Subset repair is an important data cleaning technique that enforces integrity constraints by deleting a minimal number of conflicting tuples, yet multiple minimal repairs often exist. Density-based methods address this ambiguity by favoring repairs that preserve dense, high-quality data regions; however, their effectiveness is limited by density bias from dirty clusters, high computational cost, and uniform attribute weighting. We propose a topology-aware approximate subset repair framework based on a joint density-conflict penalty model. The framework integrates three key components. First, a two-layer conflict detection strategy combines attribute inverted indexes with CFD rule grouping to efficiently identify violations. Second, we introduce EntroCFDensity, a density metric that incorporates information entropy and CFD weights to dynamically adjust attribute importance and reduce homogeneity bias. Third, a conflict degree measure is defined to complement local density, enabling a topology-adaptive penalty mechanism with dynamic weight allocation guided by the coefficient of variation. The conflict graph is further decomposed into independent subgraphs, transforming global repair into tractable local subproblems. Based on this framework, we develop two algorithms: PPIS, a scalable heuristic, and MICO, a mixed-integer programming method with theoretical guarantees. Experimental results show that our approach improves repair accuracy and robustness while effectively preserving high-quality data.

</details>


<div id='Ziniu Wu'></div>

# Ziniu Wu [[Back]](#toc)

### [5] [Synopsis-Alloyed Index for Exact and Approximate Query Processing](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/11323511/11316635.pdf&hl=zh-CN&sa=X&d=14646791791491727212&ei=N_13aeSDI6Oi6rQPoMCXoAE&scisig=AHkA5jRPszudbQLTH4RygZXN4FwX&oi=scholaralrt&hist=Pxo5FIAAAAAJ:11734074576040036222:AHkA5jT4qH64J8nZejvQlyvZo1xT&html=&pos=0&folt=rel)
*M Takata,H Yuasa,K Goda*

Main category: Ziniu Wu

TL;DR: 该论文提出了一种名为Synopsis-alloyed Index（SAI）的新数据结构，通过在现有索引中嵌入概要信息（synopsis），支持高效返回精确或近似查询结果，并在PostgreSQL中通过FDW原型验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统结构化数据库系统（如使用B+树）主要优化精确查询，但在许多分析场景中，用户更关注查询速度并接受高质量的近似结果。为弥合这一差距，作者希望设计一种既能利用现有索引结构又能支持高效近似查询的数据结构。

Method: 作者提出SAI，将概要信息直接嵌入到现有索引结构中，并设计了两种查询方法SAS和SAS+，分别用于返回精确和近似结果。通过在PostgreSQL中实现一个Foreign Data Wrapper（FDW）原型来集成SAI。

Result: 实验表明，当查询条件和所需导出属性可由概要信息满足时，SAI在近似查询上比原生PostgreSQL快达97.9%。

Conclusion: 将概要信息与索引结构融合是一种有效提升分析型近似查询性能的方法，SAI在保持兼容性的同时显著加速了查询处理，具有实际部署价值。

Abstract: Structured database systems, which organize business data, widely adopt data structures like a B+-tree to speed up selective queries. However, users in many analytical scenarios increasingly value query speed and are satisfied with high-quality approximate answers. To bridge this gap, this paper introduces the Synopsis-alloyed Index (SAI), a novel data structure that incorporates synopsis (i.e., summary or abstraction information of concerned table records) directly into existing index structures. We design two query methods, SAS and SAS+, which exploit the embedded synopsis to return exact or approximate results more efficiently than traditional approaches. To demonstrate practical viability, we realize SAI within PostgreSQL through a Foreign Data Wrapper (FDW) prototype. Experiments show that our approach achieves up to 97.9% faster performance on approximate queries compared with baseline PostgreSQL when the synopsis satisfies the query constraints and required derivative attributes.

</details>


<div id='learned "cost model"'></div>

# learned "cost model" [[Back]](#toc)

### [6] [GAS: A scheduling primitive dependency analysis-based cost model for tensor program optimization](https://scholar.google.com/scholar_url?url=https://www.sciencedirect.com/science/article/pii/S1383762126000391&hl=zh-CN&sa=X&d=14149205223053405269&ei=cKB3aerIB4eUywS5-prpDw&scisig=AHkA5jQWUKtg9HsraYXwlC_QQWS3&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=0&folt=kw-top)
*Y Hu,A Xie,Y Wang,Z Li,Z Cheng,J Tang*

Main category: learned "cost model"

TL;DR: 本文提出了一种新的在线学习代价模型方法，用于自动优化张量程序调度，克服了现有离线和在线方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有张量程序自动调度中的代价模型存在明显缺陷：离线模型依赖大量预收集数据，泛化能力差且设备相关；在线模型依赖手工特征，耗费大量人力与专业知识。因此，亟需一种更高效、通用且自动化的代价建模方法。

Method: 提出一种基于在线学习的自适应代价模型，通过自动提取调度特征并结合少量运行时反馈进行快速模型更新，从而在无需大量预训练数据或人工特征工程的情况下有效指导搜索。

Result: 在多个硬件平台和深度学习模型上的实验表明，该方法在调度性能上优于现有主流自动调度器（如Ansor、TVM等），同时显著减少了对人工干预和预收集数据的依赖。

Conclusion: 所提方法有效解决了现有代价模型在泛化性、自动化程度和效率方面的不足，为高性能张量程序的自动优化提供了更实用的解决方案。

Abstract: Automatically generating high-performance tensor programs has become a promising approach for deploying deep neural networks. A key challenge lies in designing an effective cost model to navigate the vast scheduling search space. Existing approaches typically fall into two categories, each with limitations: offline learning cost models rely on large pre-collected datasets, which may be incomplete or device-specific, and online learning cost models depend on handcrafted features, requiring substantial manual effort and expertise …

</details>


### [7] [Agent-Based Generative AI Model for Cost-Aware Automation in Machine Learning Pipelines](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/10820123/11261512.pdf&hl=zh-CN&sa=X&d=6337812190287085073&ei=cKB3aerIB4eUywS5-prpDw&scisig=AHkA5jQW5S9Ke55WkzSeNCxfYlCy&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=2&folt=kw-top)
*A Sindhu,S Arumugam*

Main category: learned "cost model"

TL;DR: 提出了一种基于智能体的生成式AI模型，用于在AutoML中实现成本感知的自动化，在保证性能的同时优化计算、资源和财务效率。


<details>
  <summary>Details</summary>
Motivation: 传统AutoML系统仅关注性能指标，忽视了计算与财务成本，难以满足企业及云环境中对经济高效、可持续AI的需求。

Method: 构建一个智能体，利用生成式AI的自适应推理能力，实时监控执行指标、性能阈值和资源使用情况，并根据任务难度与预算限制动态推荐和激活合适的模型配置，进行实时成本-性能权衡分析。

Result: 在多个数据集上的实验表明，该系统在不牺牲性能的前提下，显著提升了计算效率、资源利用率和财务效率。

Conclusion: 该方法将成本感知与自适应智能相结合，为跨领域、多工作负载的经济优化型AutoML解决方案奠定了基础，尤其适用于企业级和云环境中的可持续AI开发。

Abstract: The proposed agent-based generative AI model addresses the increasing requirement for cost-aware automation in machine learning pipelines. The traditional AutoML systems focus on performance metrics without considering the associated computational and financial costs. The model establishes an intelligent agent to track execution metrics and performance thresholds and resource utilization in real-time. The adaptive reasoning abilities of Generative AI enable the agent to suggest and activate suitable model configurations which match both task difficulty levels and financial limitations. The system performs real-time cost-performance trade-off analysis to optimize model selection and tuning processes. The system validates its performance through experimental testing on multiple datasets which demonstrates improved computational efficiency and resource management and financial efficiency without compromising performance. The approach supports sustainable AI development especially in enterprise and cloud-based environments. The combination of cost-awareness with adaptive intelligence creates a foundation for AutoML solutions that scale across different domains and workloads while remaining economically optimized.

</details>


### [8] [Research on the Impact Mechanism of ESG Performance on Corporate Financing Costs-Machine Learning Method Based on XGBoost Model](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11331992/&hl=zh-CN&sa=X&d=14516258386485153066&ei=cKB3aerIB4eUywS5-prpDw&scisig=AHkA5jSr2-ZVxtVyaTv5RSMcp77A&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=3&folt=kw-top)
*Z Xiao*

Main category: learned "cost model"

TL;DR: 本文通过因果推断方法研究企业ESG表现对融资成本的影响，发现环境与治理维度在短期内显著降低融资成本。


<details>
  <summary>Details</summary>
Motivation: 在绿色金融背景下，厘清企业ESG表现如何影响融资成本，有助于理解可持续发展对企业价值的作用机制，并为政策制定和企业实践提供依据。

Method: 基于中国A股上市公司数据，构建面板固定效应模型，引入XGBoost框架结合后门调整公式控制混杂变量以识别ESG对融资成本的因果效应；采用Bootstrap重采样进行稳健性检验，并结合Granger因果分析揭示其时效性与动态特征；同时利用XGBoost对融资成本决定因素及ESG各子维度重要性进行排序分析。ESG数据来自MSCI、Refinitiv和Bloomberg等主流评级机构，并经标准化与Winsorize处理。

Result: 研究发现，ESG表现，尤其是环境（E）和治理（G）维度，对企业融资成本具有显著的降低作用，且该效应在短期内更为明显。

Conclusion: 本研究为绿色金融背景下企业可持续价值管理提供了实证证据与方法论支持，强调了提升ESG表现特别是环境与治理水平对降低融资成本的重要性。

Abstract: This paper aims to explore the impact mechanism of corporate ESG (environment, social and governance) performance on financing costs, and introduces causal inference methods to improve identification accuracy. First, based on the data of Chinese A-share listed companies, a panel fixed effect model is constructed, and the XGBoost framework is introduced to identify the causal effect of ESG on financing costs, and the confounding variable bias is controlled by the Backdoor Adjustment formula. Secondly, this paper uses Bootstrap resampling for robustness testing, and combines Granger causal analysis to reveal the timeliness and dynamic characteristics of ESG impact. On this basis, the XGBoost algorithm is introduced to rank and analyze the determinants of financing costs, and further verify the importance of each sub-dimension of ESG. At the data level, ESG data comes from mainstream rating agencies such as MSCI, Refinitiv and Bloomberg, and is standardized and winsorized by -score. The study found that ESG, especially the environmental and governance dimensions, has a significant positive impact on reducing corporate financing costs, and is more significant in the short term. This paper provides empirical evidence and methodological support for corporate sustainable value management under the background of green finance.

</details>


### [9] [FASP: A Fast and Accurate Framework for Schedule Performance Evaluation](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11322908/&hl=zh-CN&sa=X&d=4191261919980732062&ei=cKB3aerIB4eUywS5-prpDw&scisig=AHkA5jQp6ZFDCrxvByndeeFGlHHv&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=4&folt=kw-top)
*Q Lan,A Ren,Z Wang,W Li,H Zhu,Y Tan,D Liu…*

Main category: learned "cost model"

TL;DR: FASP is a fast and accurate framework for evaluating DNN schedule performance using compact Abstract Syntax Trees (ASTs), achieving lower evaluation errors and better schedule latency.


<details>
  <summary>Details</summary>
Motivation: Existing cost models for DNN schedule performance evaluation suffer from high overhead or low accuracy, limiting inference efficiency; thus, a more accurate and efficient evaluation method is needed.

Method: FASP employs three key techniques: (1) redundancy-aware AST reduction to generate compact ASTs, (2) feature extraction from compact ASTs considering computation nodes, loop nodes, and their structural relationships, and (3) composition-similarity-driven AST classification with class-specific cost models.

Result: Experiments demonstrate FASP achieves evaluation errors as low as 6% in both single-model and cross-model settings and produces high-performance schedules with reduced latency.

Conclusion: FASP effectively addresses the limitations of prior cost models by significantly improving evaluation accuracy and speed, thereby enhancing deep learning compiler efficiency.

Abstract: With the widespread application of deep neural networks, improving inference efficiency has become increasingly critical. To speed up the inference, deep learning compilers search for high-performance schedules for the DNN tensor programs. During the process, cost models have been extensively studied to evaluate the performance of the schedules, such that high-performance ones can be efficiently obtained. However, existing methods suffer from either high overhead or low accuracy of performance evaluation, both of which limit the efficiency of the final schedule. To address these issues, we propose FASP, a fast and accurate framework for schedule performance evaluation, based on Abstract Syntax Trees (ASTs). First, we propose a redundancy-aware ASTs reduction method to generate compact ASTs for more accurate feature extraction. Second, we propose a feature extraction method based on compact ASTs, which extracts features by accounting for computation nodes, loop nodes, and their structural relationships. Third, we propose a composition-similarity-driven ASTs classification method and a class-specific cost model architecture for more accurate performance evaluation. FASP overcomes the limitations of prior methods by significantly reducing evaluation errors. Experiments show its excellent performance in both single-model and cross-model evaluation, with errors ranging from 6 % to . Moreover, FASP can obtain high-performance schedules with lower latency.

</details>


### [10] [Autonomous Flight Control for UAV Swarm Using Evolutionary Multi-Agent Multi-Objective Reinforcement Learning](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11300283/&hl=zh-CN&sa=X&d=17782253392893200509&ei=cKB3aerIB4eUywS5-prpDw&scisig=AHkA5jQ4QfuDW8y4IXHAChVGQCn_&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=7&folt=kw-top)
*L Feng,H Zheng,Y Zhao,F Zhou,W Li,F He*

Main category: learned "cost model"

TL;DR: 本文提出了一种基于进化多智能体多目标强化学习（EMAMORL）的分布式无人机群自主控制方法，以在动态低空环境中高效协调大规模无人机群，同时优化控制成本与服务激活速度。


<details>
  <summary>Details</summary>
Motivation: 随着低空经济的发展，大规模无人机群在多样化应用场景中需求激增，亟需解决在部分可观测、动态干扰环境下实现高效、精准协同飞行控制的挑战，尤其在多目标优化（如控制成本与服务响应速度）方面传统强化学习方法效率不足。

Method: 作者提出EMAMORL方法，结合分布式智能与多目标强化学习，在单次训练迭代中生成面向不同目标偏好的多个策略，降低通信与控制开销；在线推理阶段，各无人机基于预训练策略进行实时决策。

Result: 仿真实验表明，EMAMORL在生成高质量Pareto最优策略方面优于基线进化算法，并在存在风扰等动态低空环境中保持鲁棒性能。

Conclusion: 所提出的EMAMORL框架有效解决了低空动态环境下无人机群的多目标分布式控制问题，为大规模无人机系统在复杂场景中的自主协同提供了可行方案。

Abstract: With the rapid development of the low-altitude economy, there is a growing demand for large-scale uncrewed aerial vehicle (UAV) swarms to support diverse applications. These low-altitude operational scenarios require precise and efficient UAV swarm coordination, making autonomous flight control a key challenge. In this work, we investigate a distributed UAV swarm flight control problem in which each UAV autonomously makes decisions based on partial observations of neighboring UAVs and the surrounding environment. This problem involves multi-objective optimization, as the goal is to simultaneously minimize the cost of UAV control and maximize the speed of UAV service activation. To address the inefficiency of traditional reinforcement learning for this multi-objective problem when confronted with fluctuating low-altitude environmental conditions, we propose a distributed autonomous control method based on evolutionary multi-agent multi-objective reinforcement learning (EMAMORL). This approach integrates distributed intelligence with multi-objective reinforcement learning to generate numerous policies for distinct preferences for different objectives in a single iteration while reducing communication and control overheads. During the online inference phase, agents use these trained policies for real-time decision-making. Simulation results show that EMAMORL outperforms baseline evolutionary algorithms in generating high-quality Pareto-optimal policies and maintains robust performance in dynamic low-altitude environments with wind disturbances.

</details>


### [11] [VersaAccel: A Versatile Configurable Accelerator for Diverse Sparse-Dense Matrix Operators](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11272451/&hl=zh-CN&sa=X&d=3998206704442045118&ei=cKB3aerIB4eUywS5-prpDw&scisig=AHkA5jTfgip8nxuH6JMETrcS8PsC&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=9&folt=kw-top)
*M Tang,M Wen*

Main category: learned "cost model"

TL;DR: 本文提出VersaAccel，一种可配置的加速器，支持稀疏与稠密矩阵运算的四种配置，并通过轻量级代价模型动态选择最优配置，在性能与能效间取得平衡，显著优于现有主流加速器。


<details>
  <summary>Details</summary>
Motivation: 现有加速器通常针对特定类型（稠密或稀疏）的矩阵运算进行优化，在混合运算场景下表现不佳；而支持多类型运算的加速器又往往缺乏灵活性且性能不理想。因此，亟需一种既能高效处理多种矩阵运算类型，又能根据任务需求动态调整配置的通用加速架构。

Method: 设计了VersaAccel，一种支持四种配置的可重构加速器，每种配置针对不同类型的矩阵运算（如MV、MM、SPMV、SpMM、SpMSpM）进行优化。引入基于轻量级代价模型的自适应配置选择机制，该模型显式评估各配置在性能与能耗之间的权衡，从而动态选择最合适的配置。

Result: 实验表明，VersaAccel在多种矩阵运算上平均实现3.10倍的性能/面积提升，在完整模型（ResNet18、VGG16、LLaMA2-7B、BERT-Base）评估中达到4.06倍的性能/面积提升，显著优于当前主流加速器。

Conclusion: VersaAccel通过灵活的配置机制和高效的自适应调度策略，有效解决了混合稀疏-稠密矩阵运算场景下的加速难题，在性能和能效方面均取得显著优势，为深度学习等应用提供了高效硬件支持。

Abstract: Matrix operators are fundamental to various applications, particularly in deep learning. While early models relied on dense operations, techniques like pruning have introduced sparsity, leading to a mix of dense and sparse operator types. Most existing accelerators are specialized for specific operators and perform poorly in mixed scenarios, while those supporting multiple operators often lack flexibility and suffer from suboptimal performance. To overcome these limitations, we propose VersaAccel, a configurable accelerator for sparse and dense matrix operators. It supports four distinct configurations, each optimized for a set of operators. A key feature of our design is its adaptive configuration selection mechanism, driven by a lightweight cost model that explicitly evaluates the performance-energy trade-off between available options. This allows VersaAccel to dynamically choose the most efficient configuration—opting for higher performance when the gain outweighs the energy cost, or prioritizing energy efficiency when appropriate. Experimental results demonstrate that VersaAccel achieves an average performance/area improvement of 3.10× across multiple operators (MV, MM, SPMV, SpMM, SpMSpM) and 4.06× on full model evaluations (ResNet18, VGG16, LLaMA2-7B, BERT-Base), compared to mainstream accelerators.

</details>


### [12] [AI-Augmented Material Planning for Resilient & Agile Supply Chains: Managing Uncertainty and Change in New Product Introduction (NPI) Through Demand Analysis …](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/a74054a4d2e6237ad7f109a3566f15d5/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=zh-CN&sa=X&d=12454474344966296636&ei=YqF4ac7AI_DB6rQPlOuskQM&scisig=AHkA5jSLV-n7Acz5T72Dr3rQiksz&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=0&folt=kw-top)
*SA Hmeidan*

Main category: learned "cost model"

TL;DR: 本文针对新产品导入（NPI）供应链中因需求稀疏、工程变更频繁、供应商不确定性及复杂多层物料清单（BOM）所导致的高波动性，提出一种自适应且集成的规划方法，以克服传统规划系统在不稳定环境下的不足。


<details>
  <summary>Details</summary>
Motivation: 传统供应链规划系统假设环境稳定，难以应对NPI阶段特有的高不确定性与动态变化，导致企业依赖低效且易错的手动分析，亟需更灵活、集成的规划解决方案。

Method: 提出一种自适应且集成的规划方法，旨在整合NPI供应链中的多源不确定性因素，可能包括对需求、工程变更、供应商风险和BOM结构的联合建模与优化。

Result: 该方法有望显著提升NPI供应链在高波动环境下的响应能力与计划准确性，减少对手动干预的依赖。

Conclusion: 为应对NPI供应链的独特挑战，必须摒弃基于稳态假设的传统规划范式，转而采用能够动态适应不确定性的集成化规划框架。

Abstract: New Product Introduction [NPI] supply chains face high volatility driven by sparse demand, frequent engineering changes [ECOs], supplier uncertainty, and complex multi-level Bills of Materials [BOMs]. Traditional planning systems assume stability and therefore perform poorly under these conditions, leading organizations to rely on slow and error-prone manual analysis. This thesis addresses the need for an adaptive and integrated planning approach.

</details>


<div id='"query optimization"'></div>

# "query optimization" [[Back]](#toc)

### [13] [MRL-RAG: Enhancing the Accuracy of Retrieval-Augmented Generation via an Optimized Hybrid Query Retriever](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11324823/&hl=zh-CN&sa=X&d=481016353418450948&ei=cKB3aaq2Aeu7ieoPncyzoAs&scisig=AHkA5jSqn0avLN-FAeDSP6zRdxDd&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=1&folt=kw-top)
*X Li,S Wang*

Main category: "query optimization"

TL;DR: 本文提出一种基于检索增强生成（RAG）的框架，通过查询增强与双路径优化、混合检索策略及改进的稠密检索模块，在私有知识库问答任务中显著提升检索效率、答案相关性与跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着特定领域知识库规模扩大，传统RAG方法在检索效率和效果方面面临瓶颈，限制了问答系统的整体性能。因此，亟需一种能兼顾高效检索、高质量回答和良好语义理解能力的新框架。

Method: 该框架包含：（1）查询增强机制，融合查询泛化与查询分解以提升问题可解释性；（2）混合检索策略，结合稀疏与稠密检索；（3）在稠密检索中引入Matryoshka表示学习与自注意力增强，扩展编码器架构以提升语义表示能力。

Result: 在UltraDomain QA数据集（科学与医疗两个垂直领域）上，以DeepSeek-V3-Chat为基线模型，所提方法在F1-score上平均提升3个百分点，答案相关性提升约10个百分点，同时保持事实一致性。

Conclusion: 所提出的框架显著提升了私有知识库环境下问答系统的检索性能与跨域泛化能力，为高效、准确的智能问答提供了可扩展的解决方案。

Abstract: This paper presents a retrieval-augmented generation–based framework aimed at achieving efficient and accurate knowledge acquisition and question answering within private knowledge base environments. As the scale of domain-specific repositories expands, conventional RAG methods increasingly face challenges in retrieval efficiency and effectiveness, which in turn constrain overall system performance. To address these limitations, this study incorporates a query enhancement and dual-path optimization framework, integrating query generalization and query decomposition mechanisms to systematically improve the interpretability and quality of the question-answering process. In the retrieval phase, a hybrid retrieval strategy is employed by combining sparse and dense retrieval paradigms. Within the dense retrieval component, Matryoshka representation learning and self-attention enhancement are introduced to extend the conventional encoder architecture, thereby improving the model’s adaptability and semantic representation capacity. Experimental evaluations were conducted using DeepSeek-V3-Chat as the baseline model on the UltraDomain QA dataset, covering two vertical domains—science and healthcare. The proposed framework achieved an average improvement of 3 percentage points in F1-score and approximately 10 percentage points in answer relevance, while maintaining consistent factual faithfulness. The results demonstrate that the proposed approach significantly enhances retrieval performance and exhibits strong cross-domain generalization, offering a scalable and effective solution for intelligent question answering over private knowledge bases.

</details>


### [14] [Artificial Intelligence approaches for Energy Efficiency in RDF Storage–A Literature Review](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11270584/&hl=zh-CN&sa=X&d=2027181191624704486&ei=cKB3aaq2Aeu7ieoPncyzoAs&scisig=AHkA5jTrHjwEu7gPDehMYZNWxZ7X&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=2&folt=kw-top)
*W El Kaysouni,A Rabhi,H Badir*

Main category: "query optimization"

TL;DR: 该综述探讨了如何利用人工智能（如表示学习和强化学习）提升RDF数据管理系统的能效，指出当前研究多关注性能而忽视真实能耗，呼吁引入能耗感知的评估框架。


<details>
  <summary>Details</summary>
Motivation: 随着RDF数据快速增长，其存储与查询系统面临严峻的能耗挑战；现有AI方法虽提升了性能，但缺乏对实际能源消耗和环境影响的评估。

Method: 综述性分析，聚焦于AI技术（特别是表示学习与强化学习）在RDF数据管理中的应用及其对能效的潜在影响。

Result: 发现当前研究主要以速度和吞吐量为指标，很少衡量真实能耗，导致对AI方法环境效益的验证不足。

Conclusion: 强调AI在提升RDF系统可持续性方面的潜力，并呼吁未来研究纳入能耗基准测试与能效评估指标。

Abstract: The rapid increase of Resource Description Framework (RDF) data creates significant energy challenges for storage and querying systems, especially under complex workloads. This survey investigates into how to improve the energy efficiency of RDF data management using Artificial Intelligence (AI), specifically methods like representation learning and reinforcement learning. While such approaches have shown significant performance improvements, mostly by reducing costly operations like joins and scans, current research frequently analyzes them only on speed and throughput with little regard for real energy consumption. The validation of their environmental impact is limited by this gap. In addition to highlighting AI’s potential to help RDF systems become more sustainable, this study urges further research to include benchmarking frameworks and energy-aware measures.

</details>


### [15] [Towards Minimizing Human Errors in Semi-Automated SQL to NoSQL Migration](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11323267/&hl=zh-CN&sa=X&d=2983295700617262944&ei=cKB3aaq2Aeu7ieoPncyzoAs&scisig=AHkA5jS6T1Rdx5jNLeoo1fdB_AyA&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=4&folt=kw-top)
*A Kanojia,S Tanwani*

Main category: "query optimization"

TL;DR: 该论文研究了在半自动化SQL到NoSQL迁移过程中由人工干预引发的常见错误，并提出方法与建议措施以减少人为失误，提升迁移准确性、性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现代应用对可扩展性和灵活性的需求促使从关系型数据库（SQL）向NoSQL迁移，但现有半自动化迁移工具仍需大量人工干预，易引入错误，导致性能下降、数据一致性降低和停机时间增加。

Method: 分析半自动化SQL-to-NoSQL迁移中人工干预导致的典型错误来源，并提出针对性的方法论和建议性措施，以优化迁移流程。

Result: 所提措施有望提高迁移准确性、增强系统性能并降低运维风险，从而改进现有的半自动化迁移过程。

Conclusion: 通过减少人工干预带来的错误，可以显著提升SQL到NoSQL迁移的效率与可靠性，为构建更健壮的半自动化迁移框架提供支持。

Abstract: Migration from relational databases (SQL) to NoSQL is complex task and critical for handling scalability and flexibility demands of modern applications. Although various existing semi-automated models support this transition, they still need significant human intervention in schema mapping, query rewriting, join optimization and tool configuration. Manual steps frequently introduce mistakes that degrade performance, reduce data consistency and increase migration downtime. This paper investigates common error sources that occur due to manual intervention in semi-automated SQL-toNoSQL migration and attempts to minimize manual-faults through appropriate methodology and suggestive measures. These suggestive measures aim to enhance migration accuracy, enhance performance, and reduce operational risks, thereby contributing further towards enhanced semi-automated migration process

</details>


### [16] [Hybrid Data Storage Architecture: A Novel Design Approach Based on Microservices Architecture](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/6287639/11323511/11282431.pdf&hl=zh-CN&sa=X&d=2385882060426438545&ei=cKB3aaq2Aeu7ieoPncyzoAs&scisig=AHkA5jRLKW3Gi9C5yMCsSQEoLnBl&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=5&folt=kw-top)
*K Ahaidous,M Tabaa,H Hachimi,H Mouttalib…*

Main category: "query optimization"

TL;DR: 本文提出了一种基于微服务架构的混合数据持久化平台，通过统一接口整合关系型数据库、文档数据库和分布式文件存储，实现多模型数据管理的简化与自动化。


<details>
  <summary>Details</summary>
Motivation: 现代应用对延迟、可扩展性和容错性有异构需求，单一数据库系统难以兼顾；因此需要一种能融合多种数据库优势的解决方案，即多语言持久化（polyglot persistence）。

Method: 构建一个微服务架构的混合平台，抽象底层多种数据存储引擎（关系型、文档型、分布式文件系统），提供统一接口，并自动生成带完整文档的REST API以支持跨存储的CRUD操作。

Result: 初步集成测试表明，该框架显著简化了部署流程，免除了针对每种数据库的单独配置与管理，从而加速应用开发。

Conclusion: 该混合平台有效结合了各类数据库的核心优势（如事务一致性、弹性扩展、容错能力），为异构数据需求提供了一种可水平扩展且运维轻量的统一解决方案，全面性能基准测试留待后续工作。

Abstract: Due to the diverse storage and performance requirements of modern data-driven environments, choosing between relational and non-relational database systems is a complex decision, as each type offers distinct advantages and limitations depending on the application. A single database system therefore fails to deliver the necessary balance of latency, scalability, and resiliency expected by contemporary workloads. One effective solution is polyglot service persistence, an approach where multiple database engines coexist within the same system to leverage the individual strengths of each. In this paper, we introduce the development of a hybrid platform that unifies several database types—together with a distributed file store—through a micro-services architecture. This strategy yields an adaptable, horizontally scalable solution capable of satisfying heterogeneous data requirements while simplifying operational overhead. Our methodology centres on a framework that exposes a unified interface to all underlying datastores, so end users can manage relational, document, and file-based data without installing or configuring each engine individually; connection logic, driver management, and schema coordination are fully abstracted. In addition, it synthesises fully documented REST APIs for every generated schema, enabling seamless CRUD operations across all underlying stores. The hybrid system is engineered to optimise every database model’s forte: transactional consistency in relational stores, elastic growth for schema-less datasets in document stores, and built-in redundancy plus fault tolerance for large files in distributed storage. Although comprehensive benchmarks are scheduled for future work, preliminary integration tests confirm that the framework streamlines deployment workflows and accelerates application development by eliminating per-database setup tasks and management.

</details>


### [17] [Index Selectivity Distortion Under Non-Uniform Data Distributions in Oracle DB](https://scholar.google.com/scholar_url?url=https://theeducationjournals.com/index.php/jaifd/article/download/347/333&hl=zh-CN&sa=X&d=503317343850013936&ei=YqF4aYfIHfStieoP1oLE6Qk&scisig=AHkA5jSo71zE_qV-qDl6mmGHjAVH&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=0&folt=kw-top)
*J Armitage,E Harcourt*

Main category: "query optimization"

TL;DR: 该论文研究了在数据服从Zipfian或幂律分布时，Oracle数据库中索引选择性对查询优化器路径选择的影响，并提出改进方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于均匀分布假设的索引选择性估算在面对真实世界中常见的Zipfian或幂律分布数据时会产生显著偏差，导致优化器错误地选择全表扫描而非索引访问，从而影响查询性能。

Method: 论文提出一种新的索引选择性估算模型，该模型显式地考虑数据的Zipfian或幂律分布特性，通过调整选择性计算公式来更准确地反映实际数据分布，从而引导优化器做出更优的访问路径决策。

Result: 实验结果表明，所提出的方法在处理具有Zipfian或幂律分布特征的数据集时，能显著提高索引选择性的估算准确性，使优化器更频繁且正确地选择索引扫描，从而大幅降低查询响应时间。

Conclusion: 针对非均匀分布数据（特别是Zipfian分布）进行索引选择性建模是提升Oracle等关系型数据库查询优化效果的关键。该研究为优化器在真实数据场景下的决策提供了更可靠的理论基础和实践方法。

Abstract: … Index selectivity is a core factor in cost-based query optimization within Oracle databases, determining whether the optimizer chooses an index access path or a full table scan. However, when underlying data follows a Zipfian or power-law …

</details>


### [18] [Efficient Cloud-edge Collaborative Approaches to SPARQL Queries over Large RDF graphs](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.15992&hl=zh-CN&sa=X&d=3185084520544655175&ei=YqF4aYfIHfStieoP1oLE6Qk&scisig=AHkA5jR1KP-NqKbJniHFI08ScnD2&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=1&folt=kw-top)
*S Ma,P Peng,X Zhou,MT Özsu,L Zou,G Chen*

Main category: "query optimization"

TL;DR: 本文首次将边缘计算引入RDF图数据的存储与SPARQL查询处理，通过在边缘服务器上维护模式诱导子图并联合优化查询分配与资源调度，显著提升了查询效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于云的RDF图数据管理方案在带宽受限或系统负载高的环境中存在性能瓶颈，亟需更高效的架构以提升SPARQL查询性能。

Method: 提出一种结合边缘计算的新架构：1）引入“模式诱导子图”解决数据本地化问题，使边缘服务器能快速响应特定查询；2）构建综合系统模型，将查询分配与计算资源分配联合建模为混合整数非线性规划（MINLP）问题，并采用改进的分支定界算法求解。

Result: 在真实数据集和云平台上的实验表明，所提方法在查询效率上优于当前最先进的基线方法。

Conclusion: 将边缘计算与RDF图数据管理相结合是可行且有效的，通过协同优化数据放置、查询调度与资源分配，可显著提升SPARQL查询性能，为低带宽或高负载场景提供新解决方案。

Abstract: With the increasing use of RDF graphs, storing and querying such data using SPARQL remains a critical problem. Current mainstream solutions rely on cloud-based data management architectures, but often suffer from performance bottle- necks in environments with limited bandwidth or high system load. To address this issue, this paper explores for the first time the integration of edge computing to move graph data storage and processing to edge environments, thereby improving query performance. This approach requires offloading query processing to edge servers, which involves addressing two challenges: data localization and network scheduling. First, the data localization challenge lies in computing the subgraphs maintained on edge servers to quickly identify the servers that can handle specific queries. To address this challenge, we introduce a new concept of pattern-induced subgraphs. Second, the network scheduling challenge involves efficiently assigning queries to edge and cloud servers to optimize overall system performance. We tackle this by constructing a overall system model that jointly captures data distribution, query characteristics, network communication, and computational resources. Accordingly, we further propose a joint formulation of query assignment and computational resource allocation, modeling it as a Mixed Integer Nonlinear Programming (MINLP) problem and solve this problem using a modified branch-and-bound algorithm. Experimental results on real datasets under a real cloud platform demonstrate that our proposed method outperforms the state-of-the-art baseline methods in terms of efficiency. The codes are available on GitHub

</details>


### [19] [High-Performance OLAP Across the Stack: From Algorithmic Data Reduction to Cloud-and GPU-Native Execution Engines](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/3ad6647ba8c215ac85deef43b15f74f7/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=zh-CN&sa=X&d=13110096172478676035&ei=YqF4aYfIHfStieoP1oLE6Qk&scisig=AHkA5jRfNl6sniM8N5gplRnviHTW&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=2&folt=kw-top)
*Y Yang*

Main category: "query optimization"

TL;DR: 该论文针对大规模SQL分析在数据量增长、复杂连接模式及现代云与硬件基础设施下的性能瓶颈，提出了一套跨算法与系统架构的优化方法，重点减少中间数据量并提升在现代基础设施上的执行效率。


<details>
  <summary>Details</summary>
Motivation: 随着数据规模激增、连接模式日益复杂以及云和硬件基础设施不断演进，传统大规模SQL分析系统面临显著性能挑战，亟需从算法和系统层面协同优化以提升效率。

Method: 论文提出一套覆盖查询处理算法与系统执行架构的性能优化技术，特别聚焦于降低中间数据体积，并适配现代计算基础设施以提升执行效率。

Result: 通过所提出的优化方法，有效减少了中间数据量，并在现代基础设施上实现了更高效的SQL分析执行性能。

Conclusion: 跨算法与系统栈的协同优化是提升大规模SQL分析性能的关键路径，尤其在应对现代数据与硬件环境挑战时具有显著效果。

Abstract: Large-scale SQL analytics is a foundational component of modern data-driven systems, yet its performance is increasingly challenged by growing data volumes, complex join patterns, and evolving cloud and hardware infrastructures. Addressing these challenges requires innovations that span both algorithmic query processing and system-level execution architectures. This thesis presents a set of performance optimizations for large-scale SQL analytics across the algorithmic and infrastructure stacks, with a particular focus on reducing intermediate data volumes and improving execution efficiency on modern infrastructures.

</details>
