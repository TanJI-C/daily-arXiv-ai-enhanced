<div id=toc></div>

# Table of Contents

- ["query optimization"](#"query optimization") [Total: 1]
- [learned "cost model"](#learned "cost model") [Total: 4]


<div id='"query optimization"'></div>

# "query optimization" [[Back]](#toc)

### [1] [Optimus: Deployable Query Optimization via Novel SQL Rewrites](https://scholar.google.com/scholar_url?url=https://openreview.net/forum%3Fid%3DZVzYv7Qois&hl=zh-CN&sa=X&d=8376193066075901600&ei=6ZFuaenOO7ui6rQPrda9qQc&scisig=AHkA5jTLjnx1W_57zUcFKN3puylq&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=0&folt=kw-top)
*R Lone*

Main category: "query optimization"

TL;DR: Optimus enhances query optimization by expanding the action space with novel execution plan rewrites, using graph-based inductive matrix completion and a multilayer perceptron to minimize latency, all while being deployable without engine modifications.


<details>
  <summary>Details</summary>
Motivation: Traditional learned query optimizers are constrained by a fixed set of configurations, limiting the potential plan space; Optimus addresses this by dynamically discovering and utilizing new execution plan rewrites.

Method: Optimus employs graph-based inductive matrix completion and a multilayer perceptron to learn and select among newly mined execution plan rewrites, aiming to minimize query latency.

Result: Optimus demonstrates improved performance on the extended JOB benchmark by effectively selecting low-latency execution plans from an expanded action space.

Conclusion: By expanding the optimizer's action space with learnable, novel rewrites and ensuring deployability without engine changes, Optimus offers a practical and effective approach to query optimization.

Abstract: Learned database query optimizers typically optimize over a set of configurations, which limits the attainable plan space. Optimus expands the action space itself by mining novel execution plan rewrites and learns to select among these actions online. Optimus utilizes graph-based inductive matrix completion and a multilayer perceptron with the objective of minimizing latency. Crucially, the system is deployable by design: it requires no engine modifications and its rules include guard-checked compilation. On the extended JOB …

</details>


<div id='learned "cost model"'></div>

# learned "cost model" [[Back]](#toc)

### [2] [Chiplet Marketplace](https://scholar.google.com/scholar_url?url=https://chiplet-marketplace.com/library/article/exploring-the-potential-of-wireless-enabled-multi-chip-ai-accelerators&hl=zh-CN&sa=X&d=15905730971111581745&ei=6pFuadGBDbK16rQP872hoQc&scisig=AHkA5jSmEA-IqNXHZLGuwcPOmbJJ&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=2&folt=kw-top)
*E Irabor,M Musavi,A Das,S Abadal*

Main category: learned "cost model"

TL;DR: 该论文提出了一种针对机器学习模型异构性需求的架构评估方法，基于SET映射工具并定制了成本模型。


<details>
  <summary>Details</summary>
Motivation: 应对文献中不断演化的异构机器学习模型对架构设计带来的挑战。

Method: 采用基于SET的映射器（mapper）工具，并定制成本模型以评估架构开销。

Result: 实现了对不同ML模型在目标架构上部署成本的有效评估。

Conclusion: 所提出的方法能够有效支持面向异构ML模型的架构优化与选择。

Abstract: … needs of the evolving and heterogeneous pool of Machine Learning (ML) models in the literature. In … SET [30] mapper tool, and a cost model was customized to evaluate the cost of architecture. … The mapper used in SCAR is also based on SET …

</details>


### [3] [GRANII: Selection and Ordering of Primitives in GRAph Neural Networks using Input Inspection](https://scholar.google.com/scholar_url?url=https://iacoma.cs.uiuc.edu/iacoma-papers/cgo26.pdf&hl=zh-CN&sa=X&d=14789439206722274806&ei=6pFuadGBDbK16rQP872hoQc&scisig=AHkA5jQhTAP8TFaFo7sH4CZZPq-l&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=3&folt=kw-top)
*D Lenadora,V Sathia,G Gerogiannis,S Yesil…*

Main category: learned "cost model"

TL;DR: GRANII is a system that accelerates GNNs by exploring different matrix re-associations of computations, selecting the optimal sparse-dense matrix composition based on input characteristics, and achieving significant speedups in both inference and training.


<details>
  <summary>Details</summary>
Motivation: Existing GNN acceleration frameworks overlook performance opportunities arising from different matrix re-associations of GNN computations, which exhibit input-sensitive behavior. The authors aim to exploit this observation to improve execution efficiency.

Method: GRANII uses a two-stage approach: (1) an offline compilation stage that enumerates valid matrix re-associations and prunes unprofitable ones using input-oblivious techniques, and (2) an online runtime system that selects the best re-association using lightweight cost models based on input graph and embedding sizes.

Result: GRANII achieves a geometric mean speedup of 1.56× for inference and 1.4× for training across various GNN models, systems, and configurations, and is compatible with diverse implementations and sampling techniques.

Conclusion: Matrix re-association offers a promising direction for input-sensitive GNN acceleration, and GRANII effectively leverages this insight to outperform existing systems without requiring changes to underlying GNN models or frameworks.

Abstract: Over the years, many frameworks and optimization techniques have been proposed to accelerate graph neural networks (GNNs). In contrast to the optimizations explored in these systems, we observe that different matrix re-associations of GNN computations lead to novel input-sensitive performance behavior. We leverage this observation to propose GRANII, a system that exposes different compositions of sparse and dense matrix primitives based on different matrix re-associations of GNN computations and selects the best among them based on input attributes. GRANII executes in two stages:(1) an offline compilation stage that enumerates all valid re-associations leading to different sparse-dense matrix compositions and uses inputoblivious pruning techniques to prune away clearly unprofitable candidates, and (2) an online runtime system that explores the remaining candidates and uses light-weight cost models to select the best re-association based on the input graph and the embedding sizes. On a wide range of configurations, GRANII achieves a geo-mean speedup of 1.56× for inference and 1.4× for training across multiple GNN models and systems. We also show GRANII’s technique functions on diverse implementations and with techniques such as sampling.

</details>


### [4] [Algorithm-Hardware Co-Design of AdderNet Based Accelerators for Edge Intelligences](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/e98a830fca19cabb52ea92608e50c2f1/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=zh-CN&sa=X&d=9359701451023318854&ei=6pFuadGBDbK16rQP872hoQc&scisig=AHkA5jS8McOBXXsSAZQmxcsYAmhJ&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=5&folt=kw-top)
*Y Zhang*

Main category: learned "cost model"

TL;DR: 该论文提出一种算法-硬件协同设计框架，以提升资源受限的可穿戴与边缘设备中近传感器和传感器内处理的效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在开发算法与硬件时往往相互独立，导致在资源受限的可穿戴和边缘设备中处理效率低下、能耗高、延迟大。

Method: 通过构建一个集成的算法-硬件协同设计框架，使定制化算法能够充分利用专用硬件架构。

Result: 该框架显著提升了处理效率，降低了能耗，并减少了延迟。

Conclusion: 算法与硬件的协同设计对于优化资源受限环境下的近传感器和传感器内处理至关重要，能有效提升系统整体性能。

Abstract: The rapid growth of wearable and edge devices has revolutionized the way we collect and analyze data, enabling real-time insights across various applications, from health monitoring to smart environment management. This dissertation addresses the challenges associated with efficient near and in-sensor processing, emphasizing the critical role of algorithm-hardware co-design in optimizing performance within resource-constrained environments. Through a comprehensive examination of existing methodologies, this research highlights the inefficiencies that arise when algorithms and hardware are developed in isolation. By proposing an integrated co-design framework, the study demonstrates how tailored algorithms can leverage specialized hardware architectures to significantly enhance processing efficiency, reduce energy consumption, and minimize latency.

</details>


### [5] [Advanced Techniques for Hall Thruster Research and Development](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/74c2087cd9103554c88e2786f10dd3c5/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=zh-CN&sa=X&d=13511889157824109156&ei=6pFuadGBDbK16rQP872hoQc&scisig=AHkA5jRWGUncZsHn2RHmPasitIDN&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=6&folt=kw-top)
*P Thoreau*

Main category: learned "cost model"

TL;DR: 本文综述了霍尔推力器运行表征的四种先进方法，旨在提升其在研发与飞行任务中的测试效率与精度。


<details>
  <summary>Details</summary>
Motivation: 尽管霍尔推力器自1972年首次商业飞行以来已取得显著发展，但其运行表征方法仍相对传统，亟需更高效、快速和有效的技术以支持进一步开发与在轨应用。

Method: 提出了四种主要的先进表征方法，用于改进霍尔推力器运行状态的测试与分析。

Result: 这些新方法能够更有效地、高效地和迅速地完成对霍尔推力器运行特性的表征。

Conclusion: 通过引入四种先进表征途径，可显著提升霍尔推力器在研发和飞行阶段的性能评估能力，推动其未来应用与发展。

Abstract: Hall thrusters are the most common form of electric propulsion on spacecraft currently in Earth orbit, they offer excellent efficiency, high thrust to power, and have relatively simple power processing units. They have seen significant development since their first commercial flight in 1972, however, methods for characterizing their operation for both development and flight have remained relatively consistent. Therefore, advanced techniques have been developed to more effectively, efficiently, and expeditiously characterize thruster operation. These methods have been advanced through four primary approaches.

</details>
