<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 3]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Case Count Metric for Comparative Analysis of Entity Resolution Results](https://arxiv.org/abs/2601.02824)
*John R. Talburt,Muzakkiruddin Ahmed Mohammed,Mert Can Cakmak,Onais Khan Mohammed,Mahboob Khan Mohammed,Khizer Syed,Leon Claasssens*

Main category: cs.DB

TL;DR: 本文提出了一种名为案例计数度量系统（CCMS）的新方法和软件系统，用于在真实标签未知的情况下，系统地比较和分析两个实体解析（ER）聚类过程在同一数据集上的结果差异。


<details>
  <summary>Details</summary>
Motivation: 在实体解析任务中，当缺乏真实标签时，难以有效评估和比较不同聚类算法的性能。现有方法通常依赖于已知真值或仅提供整体指标，无法细致刻画聚类结构之间的具体变化关系。因此，需要一种能系统描述两个聚类结果之间转换模式的分析工具。

Method: CCMS通过定义四种聚类转换场景（保持不变、合并、分割、重叠），对第一个聚类过程产生的每个簇在第二个聚类过程中的演变情况进行分类计数。该系统不仅生成各类转换的统计数量，还提供分析模式，允许用户查看全部或特定类型转换的详细信息。

Result: CCMS成功应用于高校和工业界的研究项目中，能够全面刻画两个ER聚类结果之间的结构差异，并为用户提供可解释的细粒度分析，辅助算法选择与优化。

Conclusion: CCMS为无真值场景下的ER聚类结果比较提供了一种系统、可解释且实用的分析框架，弥补了传统评估方法的不足，具有良好的应用价值和推广潜力。

Abstract: This paper describes a new process and software system, the Case Count Metric System (CCMS), for systematically comparing and analyzing the outcomes of two different ER clustering processes acting on the same dataset when the true linking (labeling) is not known. The CCMS produces a set of counts that describe how the clusters produced by the first process are transformed by the second process based on four possible transformation scenarios. The transformations are that a cluster formed in the first process either remains unchanged, merges into a larger cluster, is partitioned into smaller clusters, or otherwise overlaps with multiple clusters formed in the second process. The CCMS produces a count for each of these cases, accounting for every cluster formed in the first process. In addition, when run in analysis mode, the CCMS program can assist the user in evaluating these changes by displaying the details for all changes or only for certain types of changes. The paper includes a detailed description of the CCMS process and program and examples of how the CCMS has been applied in university and industry research.

</details>


### [2] [Accurate Table Question Answering with Accessible LLMs](https://arxiv.org/abs/2601.03137)
*Yangfan Jiang,Fei Wei,Ergute Bao,Yaliang Li,Bolin Ding,Yin Yang,Xiaokui Xiao*

Main category: cs.DB

TL;DR: 本文提出Orchestra，一种基于多智能体协同的框架，通过将复杂的表格问答（TQA）任务分解为多个简单子任务，使小型开源大语言模型（LLMs）也能在TQA任务中取得接近甚至超越GPT-4的性能，显著降低使用成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的表格问答方法主要依赖昂贵的闭源大模型API，限制了其可及性；而直接将现有方法应用于小型开源LLM时，由于提示复杂度过高，导致性能大幅下降。因此，亟需一种适配小型开源模型、能有效降低任务复杂度的新方法。

Method: 提出Orchestra框架，采用多智能体架构，将复杂的TQA任务通过结构化的分层工作流拆解为多个相对简单的子任务，由多个小型开源LLM智能体协同完成，从而降低每个智能体所需处理的提示复杂度。该框架基于开源多智能体平台AgentScope实现。

Result: 在多个TQA基准测试中，Orchestra显著提升了小型至中型开源LLM的性能：使用Qwen2.5-14B在WikiTQ上达到72.1%准确率，接近GPT-4的最佳结果（75.3%）；在更大规模的Qwen、Llama或DeepSeek模型上，Orchestra全面超越以往所有方法，创下新的SOTA。

Conclusion: 通过多智能体协同与任务分解，Orchestra有效释放了小型开源大语言模型在表格问答任务中的潜力，实现了高质量、低成本的TQA解决方案，为资源受限场景下的应用提供了可行路径。

Abstract: Given a table T in a database and a question Q in natural language, the table question answering (TQA) task aims to return an accurate answer to Q based on the content of T. Recent state-of-the-art solutions leverage large language models (LLMs) to obtain high-quality answers. However, most rely on proprietary, large-scale LLMs with costly API access, posing a significant financial barrier. This paper instead focuses on TQA with smaller, open-weight LLMs that can run on a desktop or laptop. This setting is challenging, as such LLMs typically have weaker capabilities than large proprietary models, leading to substantial performance degradation with existing methods.
  We observe that a key reason for this degradation is that prior approaches often require the LLM to solve a highly sophisticated task using long, complex prompts, which exceed the capabilities of small open-weight LLMs. Motivated by this observation, we present Orchestra, a multi-agent approach that unlocks the potential of accessible LLMs for high-quality, cost-effective TQA. Orchestra coordinates a group of LLM agents, each responsible for a relatively simple task, through a structured, layered workflow to solve complex TQA problems -- akin to an orchestra. By reducing the prompt complexity faced by each agent, Orchestra significantly improves output reliability.
  We implement Orchestra on top of AgentScope, an open-source multi-agent framework, and evaluate it on multiple TQA benchmarks using a wide range of open-weight LLMs. Experimental results show that Orchestra achieves strong performance even with small- to medium-sized models. For example, with Qwen2.5-14B, Orchestra reaches 72.1% accuracy on WikiTQ, approaching the best prior result of 75.3% achieved with GPT-4; with larger Qwen, Llama, or DeepSeek models, Orchestra outperforms all prior methods and establishes new state-of-the-art results across all benchmarks.

</details>


### [3] [SpANNS: Optimizing Approximate Nearest Neighbor Search for Sparse Vectors Using Near Memory Processing](https://arxiv.org/abs/2601.03229)
*Tianqi Zhang,Flavio Ponzina,Tajana Rosing*

Main category: cs.DB

TL;DR: SpANNS 是一种基于 CXL Type-2 近内存架构的稀疏近邻搜索（sparse ANNS）加速方案，通过专用控制器与计算型 DIMM 协同工作，在保持高精度的同时实现比当前 CPU 基线快 15.2–21.6 倍的性能。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏近邻搜索严重依赖 CPU 实现，难以扩展，而混合检索系统在信息检索中日益普及，亟需高效、可扩展的稀疏向量搜索硬件加速方案。

Method: 提出 SpANNS 架构，结合混合倒排索引、高效的查询管理与运行时优化，部署于 CXL Type-2 近内存平台；其中专用控制器负责查询解析与聚类过滤，计算型 DIMM 在数据附近执行索引遍历与距离计算。

Result: 在多个基准测试中，SpANNS 相较最先进的 CPU 基线实现 15.2 倍至 21.6 倍的加速效果，显著提升稀疏向量搜索的效率与可扩展性。

Conclusion: SpANNS 有效解决了稀疏 ANNS 的性能瓶颈，为混合检索系统提供了高效、可扩展的硬件加速方案，推动了向量数据库在高维稀疏场景下的实际应用。

Abstract: Approximate Nearest Neighbor Search (ANNS) is a fundamental operation in vector databases, enabling efficient similarity search in high-dimensional spaces. While dense ANNS has been optimized using specialized hardware accelerators, sparse ANNS remains limited by CPU-based implementations, hindering scalability. This limitation is increasingly critical as hybrid retrieval systems, combining sparse and dense embeddings, become standard in Information Retrieval (IR) pipelines. We propose SpANNS, a near-memory processing architecture for sparse ANNS. SpANNS combines a hybrid inverted index with efficient query management and runtime optimizations. The architecture is built on a CXL Type-2 near-memory platform, where a specialized controller manages query parsing and cluster filtering, while compute-enabled DIMMs perform index traversal and distance computations close to the data. It achieves 15.2x to 21.6x faster execution over the state-of-the-art CPU baselines, offering scalable and efficient solutions for sparse vector search.

</details>
