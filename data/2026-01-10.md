<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 3]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [Structural Indexing of Relational Databases for the Evaluation of Free-Connex Acyclic Conjunctive Queries](https://arxiv.org/abs/2601.04757)
*Cristian Riveros,Benjamin Scheidt,Nicole Schweikardt*

Main category: cs.DB

TL;DR: 本文提出了一种基于数据库内部结构对称性的新型索引结构，通过构建辅助数据库 $D_{col}$，可在预处理时间与 $D_{col}$ 大小成线性关系的前提下，对任意自由连接无环合取查询（fc-ACQ）实现常数延迟枚举或计数。该索引利用关系着色精化（relational color refinement）技术，其大小在许多情况下远小于原始数据库，甚至可为常数。


<details>
  <summary>Details</summary>
Motivation: 传统索引方法（如B+树）依赖值或顺序信息，无法有效利用数据库元组间的结构对称性。作者旨在开发一种能捕捉并利用这些内部结构对称性的索引机制，以提升fc-ACQ查询的评估效率，特别是在预处理和查询延迟方面取得优于数据库规模的性能。

Method: 提出一种新索引结构，其核心是基于Scheidt和Schweikardt（2025）提出的“关系着色精化”方法构建辅助数据库 $D_{col}$。该方法通过对数据库元组进行着色以识别结构对称性，$D_{col}$ 的大小等于着色后的颜色数。利用 $D_{col}$ 进行线性时间预处理后，支持对任意fc-ACQ进行常数延迟枚举或计数。

Result: 对于任意fc-ACQ，可在 $O(|D_{col}|)$ 预处理时间内实现常数延迟枚举或答案计数。$D_{col}$ 的大小至多为 $|D|$，但在具有丰富结构对称性的数据库中（如二叉树、正则图）可显著更小（对数级甚至常数级）。这是首个利用数据库内部结构对称性实现优于数据库规模查询性能的基础性索引结果。

Conclusion: 本文首次建立了基于数据库内部结构对称性的索引理论，通过关系着色精化构建紧凑辅助结构 $D_{col}$，实现了对fc-ACQ类查询的高效评估。该方法在保持最坏情况线性开销的同时，在结构规则的数据上获得显著性能优势，为数据库索引设计开辟了新方向。

Abstract: We present an index structure to boost the evaluation of free-connex acyclic conjunctive queries (fc-ACQs) over relational databases. The main ingredient of the index associated with a given database $D$ is an auxiliary database $D_{col}$. Our main result states that for any fc-ACQ $Q$ over $D$, we can count the number of answers of $Q$ or enumerate them with constant delay after a preprocessing phase that takes time linear in the size of $D_{col}$.
  Unlike previous indexing methods based on values or order (e.g., B+ trees), our index is based on structural symmetries among tuples in a database, and the size of $D_{col}$ is related to the number of colors assigned to $D$ by Scheidt and Schweikardt's "relational color refinement" (2025). In the particular case of graphs, this coincides with the minimal size of an equitable partition of the graph. For example, the size of $D_{col}$ is logarithmic in the case of binary trees and constant for regular graphs. Even in the worst-case that $D$ has no structural symmetries among tuples at all, the size of $D_{col}$ is still linear in the size of $D$.
  Given that the size of $D_{col}$ is bounded by the size of $D$ and can be much smaller (even constant for some families of databases), our index is the first foundational result on indexing internal structural symmetries of a database to evaluate all fc-ACQs with performance potentially strictly smaller than the database size.

</details>


### [2] [LGTD: Local-Global Trend Decomposition for Season-Length-Free Time Series Analysis](https://arxiv.org/abs/2601.04820)
*Chotanansub Sophaken,Thanadej Rattanakornphan,Piyanon Charoenpoonpanich,Thanapol Phungtua-eng,Chainarong Amornbunchornvej*

Main category: cs.DB

TL;DR: LGTD is a season-length-free time series decomposition method that models seasonal patterns as emergent from adaptive local trends, eliminating the need for predefined or estimated season lengths and improving robustness in heterogeneous and irregular time series.


<details>
  <summary>Details</summary>
Motivation: Existing seasonal-trend decomposition methods often require user-specified or estimated season lengths and assume stable periodicity, which limits their robustness and applicability in real-world scenarios with drifting, intermittent, or multi-scale seasonal patterns.

Method: LGTD decomposes a time series into a smooth global trend, adaptive local linear trends (via an error-driven module called AutoTrend) that implicitly induce seasonal structure, and a residual component—without requiring any explicit season length input.

Result: Experiments on synthetic data show LGTD achieves robust and balanced decomposition performance across various seasonal settings (fixed, transitive, variable), outperforming period-based methods especially when seasonality is irregular or drifting; the method also scales linearly with time series length.

Conclusion: LGTD provides a more flexible, automated, and scalable approach to time series decomposition by treating seasonality as emergent rather than predefined, enhancing deployability in large and heterogeneous time series collections.

Abstract: Time series decomposition into trend, seasonal structure, and residual components is a core primitive for downstream analytics such as anomaly detection, change-point detection, and forecasting. However, most existing seasonal-trend decomposition methods rely on user-specified or estimated season lengths and implicitly assume stable periodic structure. These assumptions limit robustness and deployability in large, heterogeneous collections where recurring patterns may drift, appear intermittently, or exist at multiple time scales.
  We propose LGTD (Local-Global Trend Decomposition), a season-length-free decomposition framework that represents a time series as the sum of a smooth global trend, adaptive local trends whose recurrence induces implicit (emergent) seasonal structure, and a residual component. Rather than explicitly modeling seasonality through a fixed or estimated period, LGTD treats seasonal structure as an emergent property arising from repeated local trend regimes. Concretely, LGTD first estimates a global trend capturing long-term evolution, then applies AutoTrend, an adaptive error-driven local linear trend inference module, to segment the detrended signal into short-lived piecewise-linear regimes. Residuals are obtained after removing both global and local trends.
  By eliminating manual season-length specification, LGTD supports automated, low-touch deployment across time series with irregular, drifting, or weakly periodic structure. We analyze computational complexity and show that LGTD scales linearly with series length under mild conditions. Experiments on synthetic benchmarks demonstrate robust and balanced decomposition performance across fixed, transitive, and variable season-length settings, especially where period-based methods degrade.

</details>


### [3] [Rule Rewriting Revisited: A Fresh Look at Static Filtering for Datalog and ASP](https://arxiv.org/abs/2601.05108)
*Philipp Hanisch,Markus Krötzsch*

Main category: cs.DB

TL;DR: 该论文重新审视并推广了1986年由Kifer和Lozinskii提出的Datalog静态过滤方法，使用现代术语和更通用的过滤谓词，并将其扩展至回答集编程（ASP）。虽然通用方法具有双指数复杂度，但作者提出了可处理的近似算法，在典型场景下仍能显著提升规则系统在真实数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 静态过滤作为一种数据无关的Datalog优化技术，尽管早期已被提出，但在近期研究与系统开发中被忽视，其特例甚至被独立重复发现。因此，有必要回顾原始方法并加以现代化和推广。

Method: 采用更新后的术语和更通用的过滤谓词重新表述原始静态过滤方法，并将其适用范围扩展到回答集编程（ASP）；同时设计了复杂度更低的可处理近似算法以应对一般情况下的高计算复杂性。

Result: 所提出的通用静态过滤方法在理论上比经典方法更强大但复杂度更高（一般为双指数，有界元数下为单指数）；而其近似算法在典型用例中仍能带来数量级级别的性能提升。

Conclusion: 静态过滤是一种被低估的重要优化技术，通过适当近似可在现代逻辑编程系统（如ASP）中实现显著性能增益，值得在理论与实践中重新关注。

Abstract: Static filtering is a data-independent optimisation method for Datalog, which generalises algebraic query rewriting techniques from relational databases. In spite of its early discovery by Kifer and Lozinskii in 1986, the method has been overlooked in recent research and system development, and special cases are being rediscovered independently. We therefore recall the original approach, using updated terminology and more general filter predicates that capture features of modern systems, and we show how to extend its applicability to answer set programming (ASP). The outcome is strictly more general but also more complex than the classical approach: double exponential in general and single exponential even for predicates of bounded arity. As a solution, we propose tractable approximations of the algorithm that can still yield much improved logic programs in typical cases, e.g., it can improve the performance of rule systems over real-world data in the order of magnitude.

</details>
