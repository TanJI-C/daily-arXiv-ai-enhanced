<div id=toc></div>

# Table of Contents

- ["query optimization"](#"query optimization") [Total: 6]
- [Google Scholar](#Google Scholar) [Total: 1]
- [learned "cost model"](#learned "cost model") [Total: 6]
- [Ziniu Wu](#Ziniu Wu) [Total: 1]
- [cs.DB](#cs.DB) [Total: 3]


<div id='"query optimization"'></div>

# "query optimization" [[Back]](#toc)

### [1] [LLM-MVs: An LLM-Enhanced Materialized Views-Based Query Rewriting System](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11299299/&hl=zh-CN&sa=X&d=7416910454197709521&ei=fM90aZmvMLui6rQPrda9qQc&scisig=AHkA5jREEZLud0VOtpMBPWW5UIxY&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=0&folt=kw-top)
*C Sun,H Hu,H Zhang,E Wu,J Yan*

Main category: "query optimization"

TL;DR: 本文提出LLM-MVs系统，结合大语言模型（LLMs）与物化视图（MVs）管理模型，通过自然语言处理提升查询重写效率，显著改善查询执行性能。


<details>
  <summary>Details</summary>
Motivation: 传统查询重写方法依赖人工定义的规则，难以充分利用物化视图（MVs）进行优化；而直接应用大语言模型（LLMs）存在规则依赖性强、复杂任务准确率低、MVs利用不足等问题。

Method: 提出LLM-MVs原型系统，利用LLMs进行自然语言处理以生成和选择MVs，并引入MVs管理模型增强LLMs在MVs推荐中的推理能力。

Result: 实验结果表明，所提方法显著提升了查询执行效率。

Conclusion: 结合LLMs与MVs管理模型可有效克服传统方法和纯LLM方法在查询重写中的局限性，为数据库查询优化提供新思路。

Abstract: Query rewriting, which aims to enhance query efficiency by modifying the structure of SQL queries without altering their results, stands as one of the pivotal research directions in the database domain. Traditional query rewriting approaches perform language-equivalent transformations based on manually predefined rewriting rules, thereby failing to fully harness the potential of Materialized Views (MVs) for query optimization. Furthermore, with the emergence of Large Language Models (LLMs), natural language interaction with LLMs can better unlock the potential of MVs in query rewriting. Nevertheless, the direct application of LLMs for query rewriting exhibits several limitations, including overreliance on predefined rules, inadequate accuracy in complex tasks, and insufficient utilization of MVs. To address these challenges, this paper proposes a prototype system called LLM-MVs, which leverages natural language processing with LLMs to generate and select MVs. To further enhance the reasoning capability of LLMs in recommending MVs, we introduce a MV management model that provides LLMs with more efficient MV options. Experimental findings demonstrate that our proposed approach substantially enhances query execution efficiency.

</details>


### [2] [ANALISIS PENGARUH PENGGUNAAN INDEX TERHADAP KINERJA QUERY PADA DATABASE MYSQL](https://scholar.google.com/scholar_url?url=https://ejournal.cibinstitut.com/index.php/kohesi/article/download/6892/6109&hl=zh-CN&sa=X&d=4033836802393613588&ei=fM90aZmvMLui6rQPrda9qQc&scisig=AHkA5jQeCnaObAZOol29m6itTup7&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=1&folt=kw-top)
*RA Eryadi,S Nadiah,D Nurhasanah,A Latipah*

Main category: "query optimization"

TL;DR: 该研究通过实验评估了索引对 MySQL 查询性能的影响，结果表明合理使用索引可使查询执行时间减少超过 90%。


<details>
  <summary>Details</summary>
Motivation: 现代信息系统面临大量数据和高频率查询的挑战，亟需提升数据库性能；索引作为一种常用优化手段，其实际效果需系统评估。

Method: 结合文献综述与实验方法，对比在有无索引条件下 SELECT（含 WHERE）、JOIN 和 ORDER BY 等典型查询的执行时间。

Result: 在所有测试场景中，使用索引均显著降低查询执行时间，性能提升超过 90%；索引有效减少了全表扫描，加速了数据检索、连接与排序。

Conclusion: 为提升 MySQL 在大数据量和高负载环境下的效率，建议在 WHERE、JOIN 和 ORDER BY 子句中频繁使用的列上创建适当索引。

Abstract: To manage large data volumes and high query frequency, modern information systems require fast and effective database performance. One popular optimization method is implementing indexes in databases to improve query performance. This study aims to assess how the use of indexes affects query performance in MySQL. The research includes a literature review and experimental methods. Tests compare the execution time of various query types such as SELECT queries with a WHERE clause, JOIN queries between tables, and ORDER BY queries in indexed and unindexed conditions. The findings indicate that the use of indexes can significantly reduce query execution time, with performance improvements exceeding 90% in all test scenarios. By minimizing full table scans, indexes help speed up data search, integration, and sorting processes. To improve the speed and efficiency of MySQL databases, especially in systems with large data sets and workloads, it is highly recommended to use appropriate indexes on columns frequently used in WHERE, JOIN, and ORDER BY clauses.

</details>


### [3] [Is Quantum Computing Ready for Real-Time Database Optimization?](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.12123&hl=zh-CN&sa=X&d=9285225533576205973&ei=fM90aZmvMLui6rQPrda9qQc&scisig=AHkA5jRDfK0IRE9TLF2LMuEpLbGM&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=2&folt=kw-top)
*H Liu,I Sabek*

Main category: "query optimization"

TL;DR: 本文提出Q2O——首个实时量子增强查询优化器，通过将连接顺序问题编码为非线性模型并利用低延迟量子退火求解器（NL-Solver）生成计划提示，引导PostgreSQL优化器生成完整执行计划。


<details>
  <summary>Details</summary>
Motivation: 随着数据量和工作负载复杂度的增加，传统数据库优化任务（如连接顺序选择）变得难以高效求解。尽管量子退火在理论上可高效探索大规模搜索空间，但早期研究因量子计算服务高开销而未能实现与数据库系统的实际集成。近期低延迟量子求解器（如NL-Solver）的出现使实时集成成为可能，但如何在效率与解质量之间取得平衡仍是系统层面的新挑战。

Method: 作者将连接顺序问题建模为非线性优化模型，利用真实数据库统计信息进行编码，并使用D-Wave提供的低延迟NL-Solver进行求解；求解结果被转换为计划提示（plan hint），用于引导PostgreSQL查询优化器生成完整的执行计划，从而实现端到端的量子增强优化流程。

Result: Q2O能够在真实数据库环境中实时处理实际查询，成功将量子退火技术集成到现有DBMS中，并在效率与解质量之间取得可行平衡。

Conclusion: 借助新兴的低延迟量子退火求解器，量子计算可实际应用于数据库查询优化；Q2O作为首个实时量子增强查询优化器，验证了该方向的可行性，为未来数据库系统与量子计算的深度融合提供了系统设计范式。

Abstract: Database systems encompass several performance-critical optimization tasks, such as join ordering and index tuning. As data volumes grow and workloads become more complex, these problems have become exponentially harder to solve efficiently. Quantum computing, especially quantum annealing, is a promising paradigm that can efficiently explore very large search spaces through quantum tunneling. It can escape local optima by tunneling through energy barriers rather than climbing over them. Earlier works mainly focused on providing an abstract representation (e.g., Quadratic Unconstrained Binary Optimization (QUBO)) for the database optimization problems (e.g., join order) and overlooked the real integration within database systems due to the high overhead of quantum computing services (e.g., a minimum 5s runtime for D-Wave's CQM-Solver). Recently, quantum annealing providers have offered more low-latency solutions, e.g., NL-Solver, which paves the road to actually realizing quantum solutions within DBMSs. However, this raises new systems research challenges in balancing efficiency and solution quality. In this talk, we show that this balance is possible to achieve. As a proof of concept, we present Q2O, the first real Quantum-augmented Query Optimizer. We show the end-to-end workflow: we encode the join order problem as a nonlinear model, a format solvable by the NL-Solver, using actual database statistics; the solution is translated into a plan hint that guides PostgreSQL's optimizer to produce a complete plan. Q2O is capable of handling actual queries in real time.

</details>


### [4] [IF-GEO: Conflict-Aware Instruction Fusion for Multi-Query Generative Engine Optimization](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.13938&hl=zh-CN&sa=X&d=10211878196272448802&ei=fM90aZmvMLui6rQPrda9qQc&scisig=AHkA5jTPoulTBw6FvLE2S9wmhYPi&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=3&folt=kw-top)
*H Zhou,JJ Chen,X Chen,J Bao,Z Chen,Y Liao*

Main category: "query optimization"

TL;DR: 本文提出IF-GEO框架，通过“发散-收敛”策略优化文档以适应多查询场景下的生成式搜索引擎优化（GEO），在有限内容预算下协调冲突的查询偏好，并引入风险感知稳定性指标评估跨查询稳定性。


<details>
  <summary>Details</summary>
Motivation: 生成式搜索引擎通过合成检索来源直接回答用户查询，但源可见性成为挑战。现有GEO方法在面对多样查询时，因查询间存在冲突且内容修改预算有限，难以同时满足多目标优化需求。

Method: IF-GEO包含两个阶段：(i) 从代表性潜在查询中挖掘不同的优化偏好；(ii) 通过冲突感知的指令融合机制协调这些偏好，生成全局修订蓝图以指导文档编辑。同时提出风险感知稳定性指标以量化跨查询稳定性。

Result: 在多查询基准测试中，IF-GEO在提升性能的同时保持了在不同检索场景下的鲁棒性和跨查询稳定性。

Conclusion: IF-GEO有效解决了多查询GEO中的冲突优化问题，为生成式搜索引擎中的源可见性优化提供了实用且稳健的解决方案。

Abstract: As Generative Engines revolutionize information retrieval by synthesizing direct answers from retrieved sources, ensuring source visibility becomes a significant challenge. Improving it through targeted content revisions is a practical strategy termed Generative Engine Optimization (GEO). However, optimizing a document for diverse queries presents a constrained optimization challenge where heterogeneous queries often impose conflicting and competing revision requirements under a limited content budget. To address this challenge, we propose IF-GEO, a "diverge-then-converge" framework comprising two phases: (i) mining distinct optimization preferences from representative latent queries; (ii) synthesizing a Global Revision Blueprint for guided editing by coordinating preferences via conflict-aware instruction fusion. To explicitly quantify IF-GEO's objective of cross-query stability, we introduce risk-aware stability metrics. Experiments on multi-query benchmarks demonstrate that IF-GEO achieves substantial performance gains while maintaining robustness across diverse retrieval scenarios.

</details>


### [5] [A study on learning-based model extraction attacks and defense methods](https://scholar.google.com/scholar_url?url=https://theses.lib.polyu.edu.hk/handle/200/14093&hl=zh-CN&sa=X&d=4426271800909848313&ei=fM90aZmvMLui6rQPrda9qQc&scisig=AHkA5jRZHCBXRiS5ZO6bAf2fAbtS&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=6&folt=kw-top)
*Y Xiao*

Main category: "query optimization"

TL;DR: 该论文系统研究了机器学习即服务（MLaaS）中模型提取攻击（MEA）的风险，揭示了模型窃取与训练数据隐私泄露之间的相互增强效应，并发现优化的初始参数和兼容架构可实现神经元级精度的模型复制，从而加剧下游攻击威胁。


<details>
  <summary>Details</summary>
Motivation: 随着MLaaS的普及，云上黑盒模型面临日益严重的模型提取攻击风险，攻击者可通过预测接口复制专有模型，进而引发知识产权盗窃、隐私泄露或对抗攻击。现有研究多聚焦于查询优化，但忽略了两个关键放大因素：模型窃取与训练数据隐私泄露的相互强化，以及初始引导对提取性能的影响。

Method: 本文通过系统性分析，首先揭示模型提取攻击与成员推断攻击之间的迭代协同机制；其次，研究优化初始参数和模型架构兼容性对提取效果的影响，验证其在神经元级别复现目标模型的能力。

Result: 研究发现，模型提取与成员推断攻击可相互增强；采用优化的初始参数和更兼容的模型架构，能使MEA在神经元层面精确复制目标模型，显著提升攻击性能，并为后续攻击提供高保真替代模型。

Conclusion: 模型提取攻击的严重性被低估，其不仅威胁知识产权，还通过与隐私攻击的耦合及神经元级复制能力，显著增强下游攻击效力。需从多角度设计防御机制以应对这一复合威胁。

Abstract: The widespread adoption of Machine Learning as a Service (MLaaS) has exposed cloud-deployed black-box models to growing security risks, particularly from model extraction attacks (MEAs). In these attacks, adversaries exploit prediction interfaces to replicate proprietary models, subsequently enabling secondary privacy breaches or adversarial attacks through extracted model insights. Driven by the intellectual property (IP) theft crisis, this thesis first systematically investigates MEA risks and then explores defense strategies from multiple perspectives.
While existing MEA research focuses on query optimization to maximize attack success, two critical attack amplifiers remain underexplored:(1) the mutual reinforcement between model theft and training data privacy leakage and (2) the impact of initial bootstrapping on extraction performance. This work reveals that model extraction and membership inference attacks, which aim to identify training data, can strengthen each other through an iterative process. Furthermore, we reveal that optimized initial parameters and more compatible model architectures enable MEAs to replicate models at the neuron level. This strategy not only boosts the performance of model extraction attacks but also redefines their severity because it provides substitute models with neuron-level precision for downstream attacks.

</details>


### [6] [xBound: Join Size Lower Bounds](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.13117&hl=zh-CN&sa=X&d=4859839600813706153&ei=fM90aZmvMLui6rQPrda9qQc&scisig=AHkA5jRH2fj0IV2AR9cFP30VUe03&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=7&folt=kw-top)
*M Stoian,T Bang,H Zhao,J Camacho*

Main category: "query optimization"

TL;DR: 该论文提出了一种双边界方法，以检测和缓解查询优化中的估算错误。


<details>
  <summary>Details</summary>
Motivation: 查询优化历经五十年研究仍被视为“未解决”问题，现有方法在估算准确性方面存在不足，亟需改进。

Method: 采用一种双边界（dual-bound）方法，在查询优化过程中识别并修正代价模型中的估算偏差。

Result: 该方法能够更有效地检测和缓解查询优化中的估算错误，从而提升查询计划选择的准确性。

Conclusion: 双边界方法为解决查询优化中长期存在的估算不准问题提供了有效途径，具有实际应用价值。

Abstract: … After five decades of research and development, query optimization remains an “unsolved" problem. As pointed out by both practitioners and researchers, … Evidently, this dual-bound approach enables us to both detect and mitigate more misestimates during query …

</details>


<div id='Google Scholar'></div>

# Google Scholar [[Back]](#toc)

### [7] [Explicit Entropic Constructions for Coverage, Facility Location, and Graph Cuts](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.12724&hl=en&sa=X&d=2298347721120755187&ei=fkp1ac2bCLuM6rQP2dOq-Ag&scisig=AHkA5jTYHfVedb5vgco4-iTNwb7D&oi=scholaralrt&hist=Pxo5FIAAAAAJ:6303853285888070373:AHkA5jQg0xFJQ1T_sclEfqikcIfn&html=&pos=0&folt=rel)
*R Iyer*

Main category: Google Scholar

TL;DR: 本文证明了多种常用单调子模函数（如集合覆盖、设施选址等）本质上是香农熵，从而建立了组合信息度量与经典信息论之间的直接联系。


<details>
  <summary>Details</summary>
Motivation: 尽管香农熵是子模函数的一个特例，而近年来提出的子模信息度量（SIMs）将信息论概念推广到一般子模函数，但尚不清楚实践中广泛使用的子模函数是否具有“熵性”（即能否表示为某些随机变量的香农熵）。本文旨在回答这一基本问题。

Method: 作者对一系列广泛应用的单调子模函数（包括集合覆盖、覆盖函数、设施选址、饱和覆盖、凹模函数及图割类目标）构造了对应的随机变量，并显式地证明这些函数可精确表示为其香农熵。

Result: 所研究的各类常用子模函数均可被实现为适当构造的随机变量的香农熵。因此，对于这些函数，子模互信息、条件增益和子模条件互信息分别等价于经典信息论中的互信息、条件熵和条件互信息。

Conclusion: 该工作表明，许多实际应用中最常见的子模目标函数本质上是熵性的，从而在组合信息度量与经典信息论之间建立了直接桥梁，为子模优化在信息论框架下的解释和应用提供了理论基础。

Abstract: Shannon entropy is a polymatroidal set function and lies at the foundation of information theory, yet the class of entropic polymatroids is strictly smaller than the class of all submodular functions. In parallel, submodular and combinatorial information measures (SIMs) have recently been proposed as a principled framework for extending entropy, mutual information, and conditional mutual information to general submodular functions, and have been used extensively in data subset selection, active learning, domain adaptation, and representation learning. This raises a natural and fundamental question: are the monotone submodular functions most commonly used in practice entropic? In this paper, we answer this question in the affirmative for a broad class of widely used polymatroid functions. We provide explicit entropic constructions for set cover and coverage functions, facility location, saturated coverage, concave-over-modular functions via truncations, and monotone graph-cut-type objectives. Our results show that these functions can be realized exactly as Shannon entropies of appropriately constructed random variables. As a consequence, for these functions, submodular mutual information coincides with classical mutual information, conditional gain specializes to conditional entropy, and submodular conditional mutual information reduces to standard conditional mutual information in the entropic sense. These results establish a direct bridge between combinatorial information measures and classical information theory for many of the most common submodular objectives used in applications.

</details>


<div id='learned "cost model"'></div>

# learned "cost model" [[Back]](#toc)

### [8] [Navigating Federated Semi-Supervised Learning in Dual Data Heterogeneity](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11295951/&hl=zh-CN&sa=X&d=2298681466154420481&ei=fM90aY31NcyQieoPxcX9yAo&scisig=AHkA5jTnyP15FgUiA1mFf_sgHaj-&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=3&folt=kw-top)
*TH Peng,WC Tai,YH Chiang,Y Ji,AC Pang*

Main category: learned "cost model"

TL;DR: 本文提出FedF3框架，通过自适应损失过滤和基于Fisher信息的稀疏选择，有效缓解联邦半监督学习中数据异构性与标注异构性共同导致的性能下降问题，在保障隐私的同时提升模型鲁棒性和通信效率。


<details>
  <summary>Details</summary>
Motivation: 在6G驱动的智能应用中，联邦学习（FL）虽能保护隐私，但面临标注数据稀缺的问题；半监督学习（SSL）可利用无标签数据，但其与FL结合形成的FSSL在非独立同分布（non-IID）数据和客户端间标注能力差异（即标注异构性）下表现不佳。现有方法通常假设所有客户端具备相似的标注能力，忽略了实际中普遍存在的“双重数据异构性”（数据分布异构 + 标注数量异构），导致全局模型性能严重下降。因此，亟需一种能在标签稀缺、隐私保护、通信受限条件下稳定运行的FSSL方法。

Method: 作者提出Federated Fisher Focus Filtering (FedF3)，基于其先前的SynFMPL方法进行增强。该框架包含两个核心阶段：（1）自适应损失过滤（Adaptive Loss Filtering）：在训练初期识别并抑制受双重异构性影响而不可靠的客户端贡献，以稳定训练过程；（2）Fisher聚焦选择（Fisher Focus Selection）：利用Fisher信息指导模型稀疏化，在满足通信预算的同时保留关键参数，维持模型精度。

Result: 实验表明，FedF3在多种异构联邦学习设置下均显著优于现有方法，有效缓解了双重数据异构性带来的负面影响，同时保持了模型个性化能力和隐私保护特性，并具备良好的通信效率。

Conclusion: FedF3通过结合自适应损失过滤与Fisher引导的稀疏选择，成功应对了联邦半监督学习中由数据异构性和标注异构性共同引发的挑战，为6G环境下资源受限、隐私敏感的智能应用提供了高效、鲁棒的训练范式。

Abstract: The rise of 6G networks brings ultra-fast communication and broad connectivity, enabling intelligent applications such as IoT, smart cities, and autonomous vehicles. However, training AI models in these environments often faces privacy concerns and limited labeled data. Federated Learning (FL) provides a privacy-preserving solution by allowing clients to collaboratively train models without sharing raw data. Yet, FL still struggles with the scarcity of labeled data due to privacy constraints. Semi-Supervised Learning (SSL) can alleviate this issue by leveraging both labeled and unlabeled data. While combining SSL and FL (FSSL) offers promise, it also introduces new challenges, such as confirmation bias and degraded performance under non-IID data distributions. Most existing FSSL methods assume uniform labeling capabilities across clients, which is rarely the case in practice. This leads to a new challenge only occur in FSSL called annotation heterogeneity, where some clients have many labeled samples while others have few or none. When combined with data heterogeneity, this dual-data heterogeneity (data and annotation heterogeneity) severely affects global model performance. Therefore, FSSL must learn under label scarcity while preserving privacy, remain stable when non-IID data is compounded by annotation heterogeneity, and stay communication-efficient for mobile deployment. In this work, we propose Federated Fisher Focus Filtering (FedF3), an enhanced framework built upon our previous SynFMPL method, to address the combination effect of dual-data heterogeneity. FedF3 introduces a two-stage strategy, Adaptive Loss Filtering stabilizes early training by suppressing unreliable contributions under dual heterogeneity, and Fisher Focus Selection preserves accuracy with Fisher-guided sparsity to meet communication budgets. Our method demonstrates robust performance improvements across diverse and heterogeneous FL settings, mitigating the negative effects of dual-data heterogeneity while preserving personalization and privacy.

</details>


### [9] [Towards Resilient AIoT–Enabled Disaster Response: A Cloud–Edge–End Semantic Communication Framework](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel8/11322805/11322871/11322943.pdf&hl=zh-CN&sa=X&d=4936834923410879034&ei=fM90aY31NcyQieoPxcX9yAo&scisig=AHkA5jTvQjblvNl4zQaApFQ3xWNB&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=5&folt=kw-top)
*C Jin,T Mai,S Huang,X Ren,F Wang,X Xiao*

Main category: learned "cost model"

TL;DR: 提出了一种云-边-端协同的语义通信框架，用于AIoT中无人机在应急场景下的高效数据传输，通过Matching-UCB算法实现动态匹配，显著降低传输负载并提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 在AIoT时代，无人机在应急场景中产生大量原始感知数据，易导致带宽受限的通信基础设施过载，影响灾害响应的时效性与可靠性。因此，亟需一种高效的数据处理与传输机制。

Method: 构建云-边-端协同的语义通信架构：无人机负责实时环境感知，移动边缘车辆进行语义过滤与资源协调，云端执行全局决策。结合匹配理论与多臂老虎机（MAB）模型，设计Matching-UCB算法，使无人机与车辆在信息不完全条件下通过重复交互学习偏好并实现稳定匹配。

Result: 理论分析证明Matching-UCB算法具有次线性后悔界并保证稳定匹配；仿真实验表明，所提框架可减少超过99%的传输负载，在社会福利和后悔值方面优于基准方法。

Conclusion: 该语义通信框架有效解决了应急场景下无人机数据传输的带宽瓶颈问题，提升了AIoT系统的可扩展性、鲁棒性与效率，为智能应急响应提供了可行的技术路径。

Abstract: In the era of Artificial Intelligence of Things (AIoT), Unmanned Aerial Vehicles (UAVs) are increasingly deployed in emergency scenarios to provide intelligent environmental sensing and rapid situational awareness. However, the massive raw sensory data generated by UAVs can easily overwhelm bandwidth-limited communication infrastructures, undermining the timeliness and reliability of disaster response. To address this challenge, we propose a cloud-edge-end collaborative semantic communication(SemCom) framework that enables UAVs, mobile edge vehicles, and cloud-based command centers to jointly deliver resilient and scalable AIoT services. In this architecture, UAVs perform real-time environmental sensing, vehicles act as mobile edge nodes for semantic filtering and resource coordination, while the cloud executes global decision-making. To optimize semantic data trading under incomplete information, we integrate matching theory with a multi-armed bandit (MAB) model and design a Matching-UCB algorithm, which allows UAVs and vehicles to dynamically learn preferences through repeated interactions. Theoretical analysis proves that Matching-UCB achieves sub-linear regret and guarantees stable matching outcomes. Simulation results further demonstrate that our semantic-aware AIoT framework reduces transmission load by more than 99% and achieves optimal matching with the highest social welfare and lowest regret among benchmarks.

</details>


### [10] [Automatic Prompt Optimization for Dataset-Level Feature Discovery](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.13922&hl=zh-CN&sa=X&d=14971627786700630512&ei=fM90aY31NcyQieoPxcX9yAo&scisig=AHkA5jTkYGlStfP-aD6XdeZkDgLR&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=6&folt=kw-top)
*A Cosma,O Szehr,D Kletz,A Antonucci,O Pelletier*

Main category: learned "cost model"

TL;DR: 该论文提出一种多智能体提示优化框架，将特征发现建模为数据集级别的提示优化问题，以自动从非结构化文本中发现可解释且具有判别性的全局特征集。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从非结构化文本中提取特征时依赖手工设计的提示或固定特征模式，缺乏自动化和泛化能力；作者旨在通过数据集级的提示优化实现自动、可解释且面向下游任务性能的特征发现。

Method: 构建一个多智能体系统，其中语言模型智能体协同完成三项任务：提出特征定义、提取特征值、基于数据集级的性能与可解释性反馈评估特征质量；通过迭代优化指令提示，生成适用于整个数据集的共享特征集，而非逐样本预测。

Result: 该方法成功实现了无需人工干预的特征发现，所生成的特征既具判别性又可解释，并在下游监督学习任务中表现优于依赖逐样本监督的传统提示优化方法。

Conclusion: 将特征发现形式化为数据集级提示优化问题，提供了一种原则性强、可扩展的自动特征工程新范式，突破了传统逐样本提示优化的局限。

Abstract: Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.

</details>


### [11] [Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.13260&hl=zh-CN&sa=X&d=17192371926797442852&ei=fM90aY31NcyQieoPxcX9yAo&scisig=AHkA5jQRy_Evwcfk1w1YtUdkEUW4&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=7&folt=kw-top)
*S Alqahtani,MT Nayeem,MTR Laskar,T Mohiuddin…*

Main category: learned "cost model"

TL;DR: 该论文主张将分词（tokenization）视为语言模型的核心设计决策，而非预处理步骤，提倡结合语言学、领域和部署需求进行分词器与模型的协同设计，并呼吁标准化评估与透明报告以提升公平性、效率与适应性。


<details>
  <summary>Details</summary>
Motivation: 当前主流的子词分词方法（如BPE）虽具可扩展性，但常与语言结构不一致、加剧偏见并在多语言和多领域场景中浪费模型容量；分词作为大语言模型的基础组件，却缺乏理论支撑且设计不统一。

Method: 提出一种上下文感知的分词框架，将分词器与模型进行协同设计，综合考虑语言学特性、应用领域和部署环境，并倡导建立标准化评估体系和透明的报告机制。

Result: 该方法有望缓解现有分词策略带来的偏差、低效和适应性差等问题，从而提升语言技术的整体性能。

Conclusion: 将分词视为核心建模问题而非技术附带事项，有助于构建更公平、高效和可适应的语言技术系统。

Abstract: Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.

</details>


### [12] [Unleashing Efficient Asynchronous RL Post-Training via Staleness-Constrained Rollout Coordination](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.12784&hl=zh-CN&sa=X&d=1183535510241298154&ei=fM90aY31NcyQieoPxcX9yAo&scisig=AHkA5jRfiGFFOVLPrL7Msaet5Wo0&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=8&folt=kw-top)
*H Li,S Lin,F Fu,Y Zhou,X Ji,Y Zhao,L Wang,J Jiang…*

Main category: learned "cost model"

TL;DR: StaleFlow 是一种新型强化学习（RL）后训练系统，通过全局一致性协议控制轨迹数据的陈旧性，并通过重构系统架构引入专用数据服务器以缓解轨迹长度差异导致的数据偏斜，在不牺牲收敛性的前提下显著提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有完全解耦的 RL 后训练系统在异步执行 rollout、reward 和 training 三个阶段时，面临两个关键数据层面的问题：一是模型参数更新滞后导致轨迹数据陈旧，影响收敛；二是轨迹长度差异造成严重数据偏斜，降低系统性能。现有方法无法统一解决这两个问题，往往需在收敛性和性能之间做出权衡。

Method: StaleFlow 提出两项核心技术：（1）全局一致性协议，追踪每条轨迹的完整生命周期以约束数据陈旧性；（2）重构系统架构，引入轨迹与参数专用的数据服务器，实现灵活的 rollout 协调。此外，设计了一系列兼顾陈旧性控制与吞吐量优化的调度策略。

Result: 实验表明，StaleFlow 相较于当前最先进的系统，在不损害收敛性的前提下，吞吐量最高提升 2.68 倍，平均提升 1.17–2.01 倍。

Conclusion: StaleFlow 成功实现了对数据陈旧性与数据偏斜的联合优化，突破了现有 RL 后训练系统在性能与收敛性之间的权衡困境，为大规模模型的高效强化学习训练提供了有效解决方案。

Abstract: Reinforcement learning (RL) post-training has become pivotal for enhancing the capabilities of modern large models. A recent trend is to develop RL systems with a fully disaggregated architecture, which decouples the three RL phases (rollout, reward, and training) onto separate resources and executes them asynchronously. However, two critical data-level concerns arise: (1) asynchronous execution leads to data staleness in trajectories (the data generated by rollout) as the model parameters used in rollout may not be up to date, which impairs RL convergence; and (2) the length variation of trajectories introduces severe data skewness, leading to workload imbalance and degraded system performance. Existing systems fail to address these two concerns in a unified manner. Techniques that tightly control data staleness often constrain effective data skewness mitigation, while aggressive data skewness mitigation tends to exacerbate data staleness. As a result, systems are forced to trade off convergence for performance, or vice versa. To address this, we propose StaleFlow, an RL post-training system that jointly tackles data staleness and skewness. First, to control staleness, StaleFlow introduces a global consistency protocol that tracks the full lifecycle of each trajectory and constrains staleness. Second, to mitigate skewness, StaleFlow re-designs the RL system architecture by constructing data servers for trajectories and parameters to achieve flexible rollout coordination. Subsequently, we develop a suite of staleness-aware, throughput-oriented strategies to enhance system performance. Evaluations show that StaleFlow achieves up to 1.42-2.68 (1.17-2.01 on average) higher throughput than state-of-the-art systems, without compromising convergence.

</details>


### [13] [Power Transformer Design Optimization using Single and Multi-Objective Evolutionary Algorithms](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11314353/&hl=zh-CN&sa=X&d=12553585365594295869&ei=fM90aY31NcyQieoPxcX9yAo&scisig=AHkA5jQsWqUCIZpE1Ln01HlpstNy&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=9&folt=kw-top)
*AW Al Hourani,MA Abido,M Kassas*

Main category: learned "cost model"

TL;DR: 本文研究了进化算法（EAs）在电力变压器设计优化中的应用，比较了多种单目标与多目标优化方法，结果表明多目标优化在成本与性能之间提供了更优的权衡。


<details>
  <summary>Details</summary>
Motivation: 在竞争激烈的制造环境中，需在满足IEEE标准的前提下，实现成本最小化和性能最大化，因此有必要探索高效的优化方法以获得最优的电力变压器设计方案。

Method: 构建并验证了一个高精度的变压器计算模型，并系统评估了遗传算法（GA）、差分进化算法（DEA）以及NSGA-II和NSGA-III等多目标进化算法在单目标和多目标约束优化问题中的性能。

Result: 多目标优化方法在成本与性能之间实现了更优的平衡，优于单目标方法；所用模型与行业标准软件高度一致，验证了其准确性。

Conclusion: 进化算法在电力变压器优化中具有显著潜力，未来可结合机器学习发展混合方法，以提升收敛速度和计算效率。

Abstract: Power transformers are critical components of electric power systems and represent significant capital investments. In a competitive manufacturing environment, achieving optimal transformer designs that comply with IEEE standards while minimizing cost and maximizing performance is essential. This paper investigates the application of Evolutionary Algorithms (EAs) for power transformer design optimization, considering both single-objective and multiobjective constrained problems. A detailed transformer calculation model is developed and validated against industrystandard software, demonstrating high accuracy. The performance of several EAs, including the Genetic Algorithm (GA), Differential Evolution Algorithm (DEA), and Nondominated Sorting Genetic Algorithms (NSGA-II and NSGAIII), is comprehensively evaluated. Results indicate that multiobjective optimization provides superior trade-offs between cost and performance, offering a more balanced and effective design approach. The study confirms the potential of EAs in power transformer optimization and outlines future research directions, including hybrid methodologies integrating EAs with machine learning to enhance convergence and computational efficiency.

</details>


<div id='Ziniu Wu'></div>

# Ziniu Wu [[Back]](#toc)

### [14] [RDMA-Oriented Learned Key-Value Store](https://scholar.google.com/scholar_url?url=https://link.springer.com/chapter/10.1007/978-981-95-2885-1_5&hl=zh-CN&sa=X&d=17436591101824921729&ei=deFzabrPHMm4ieoPof3esQc&scisig=AHkA5jTVlodRJWiCkRDhIqNcPByI&oi=scholaralrt&hist=Pxo5FIAAAAAJ:11734074576040036222:AHkA5jT4qH64J8nZejvQlyvZo1xT&html=&pos=0&folt=rel)
*Y Hua*

Main category: Ziniu Wu

TL;DR: 该论文研究了分解式内存系统中通过分离计算与内存节点以提升资源利用率和可扩展性，并提出了一种高效的数据共享与访问机制。


<details>
  <summary>Details</summary>
Motivation: 传统单体服务器架构在资源利用率、硬件扩展性和数据共享方面存在局限，而分解式内存系统通过将计算与内存解耦，有望解决这些问题。然而，如何高效地管理远程内存访问和保障性能成为关键挑战。

Method: 论文提出了一种针对分解式内存系统的新型架构或协议（如远程内存访问优化、缓存一致性机制、低延迟互连等），通过软硬件协同设计来减少访问延迟、提高带宽利用率并支持高效的数据共享。

Result: 实验结果表明，所提方法在典型工作负载下显著降低了远程内存访问延迟，提高了系统整体吞吐量，并在资源利用率和扩展性方面优于现有方案。

Conclusion: 分解式内存系统通过合理的架构设计能够有效提升数据中心的资源效率和灵活性，本文提出的优化方法为实现高性能、可扩展的分解式系统提供了可行路径。

Abstract: Disaggregated memory systems separate monolithic servers into different components, including compute and memory nodes, to enjoy the benefits of high resource utilization, flexible hardware scalability, and efficient data sharing. By …

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [15] [NL4ST: A Natural Language Query Tool for Spatio-Temporal Databases](https://arxiv.org/abs/2601.15758)
*Xieyang Wang,Mengyi Liu,Weijia Yi,Jianqiu Xu,Raymond Chi-Wing Wong*

Main category: cs.DB

TL;DR: 本文提出了NL4ST，一个支持自然语言查询（NLQ）的交互式工具，用于在时空数据库中生成有效的物理查询计划，降低非专业用户使用时空数据库的门槛。


<details>
  <summary>Details</summary>
Motivation: 随着移动计算设备和定位技术的发展，时空数据激增，但传统查询（如范围查询、最近邻查询等）需要用户具备领域知识和查询语言技能，对非专家用户构成障碍。因此，亟需支持自然语言查询的系统以提升可用性。

Method: NL4ST采用三层架构：(i) 知识库与语料库用于知识准备；(ii) 自然语言理解模块实现实体链接；(iii) 查询计划生成模块将自然语言转换为物理执行计划。

Result: 通过在四个真实和合成数据集上的验证，NL4ST能有效生成准确的时空物理查询计划，并已上线提供在线演示视频。

Conclusion: NL4ST成功弥合了非专家用户与时空数据库查询之间的鸿沟，展示了自然语言接口在复杂数据库查询中的可行性和实用性。

Abstract: The advancement of mobile computing devices and positioning technologies has led to an explosive growth of spatio-temporal data managed in databases. Representative queries over such data include range queries, nearest neighbor queries, and join queries. However, formulating those queries usually requires domain-specific expertise and familiarity with executable query languages, which would be a challenging task for non-expert users. It leads to a great demand for well-supported natural language queries (NLQs) in spatio-temporal databases. To bridge the gap between non-experts and query plans in databases, we present NL4ST, an interactive tool that allows users to query spatio-temporal databases in natural language. NL4ST features a three-layer architecture: (i) knowledge base and corpus for knowledge preparation, (ii) natural language understanding for entity linking, and (iii) generating physical plans. Our demonstration will showcase how NL4ST provides effective spatio-temporal physical plans, verified by using four real and synthetic datasets. We make NL4ST online and provide the demo video at https://youtu.be/-J1R7R5WoqQ.

</details>


### [16] [Efficient Cloud-edge Collaborative Approaches to SPARQL Queries over Large RDF graphs](https://arxiv.org/abs/2601.15992)
*Shidan Ma,Peng Peng,Xu Zhou,M. Tamer Özsu,Lei Zou,Guo Chen*

Main category: cs.DB

TL;DR: 本文首次将边缘计算引入RDF图数据的SPARQL查询处理，通过在边缘服务器上存储和处理子图以提升查询性能，并提出一种基于模式诱导子图的数据定位方法与联合优化查询分配及资源调度的MINLP模型，实验表明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于云架构的RDF图数据管理在带宽受限或系统负载高的环境中存在性能瓶颈，亟需更高效的查询处理机制。

Method: 提出“模式诱导子图”以解决边缘环境中的数据定位问题；构建综合系统模型，将查询分配与计算资源分配联合建模为混合整数非线性规划（MINLP）问题，并采用改进的分支定界算法求解。

Result: 在真实数据集和云平台上进行的实验表明，所提方法在查询效率方面显著优于现有最先进基线方法。

Conclusion: 将边缘计算融入RDF图数据管理能有效提升SPARQL查询性能，所提出的联合优化框架为未来边缘-云协同数据处理提供了可行路径。

Abstract: With the increasing use of RDF graphs, storing and querying such data using SPARQL remains a critical problem. Current mainstream solutions rely on cloud-based data management architectures, but often suffer from performance bottle- necks in environments with limited bandwidth or high system load. To address this issue, this paper explores for the first time the integration of edge computing to move graph data storage and processing to edge environments, thereby improving query performance. This approach requires offloading query processing to edge servers, which involves addressing two challenges: data localization and network scheduling. First, the data localization challenge lies in computing the subgraphs maintained on edge servers to quickly identify the servers that can handle specific queries. To address this challenge, we introduce a new concept of pattern-induced subgraphs. Second, the network scheduling challenge involves efficiently assigning queries to edge and cloud servers to optimize overall system performance. We tackle this by constructing a overall system model that jointly captures data distribution, query characteristics, network communication, and computational resources. Accordingly, we further propose a joint formulation of query assignment and computational resource allocation, modeling it as a Mixed Integer Nonlinear Programming (MINLP) problem and solve this problem using a modified branch-and-bound algorithm. Experimental results on real datasets under a real cloud platform demonstrate that our proposed method outperforms the state-of-the-art baseline methods in terms of efficiency. The codes are available on GitHub

</details>


### [17] [EAIFD: A Fast and Scalable Algorithm for Incremental Functional Dependency Discovery](https://arxiv.org/abs/2601.16025)
*Yajuan Xu,Xixian Han,Xiaolong Wan*

Main category: cs.DB

TL;DR: 本文提出EAIFD算法，通过维护差集的部分超图并将增量函数依赖（FD）发现问题转化为超图上的极小击中集枚举，结合多属性哈希表（MHT）和两阶段验证策略，显著提升性能并降低内存开销。


<details>
  <summary>Details</summary>
Motivation: 现有静态FD发现算法在数据更新时需完全重运行，效率低下；而现有增量算法则面临严重的性能与内存瓶颈。因此，亟需一种高效、可扩展的增量FD发现方法。

Method: EAIFD将增量FD发现建模为超图上的极小击中集枚举问题，避免全量重计算。其核心包括：(1) 设计多属性哈希表（MHT）存储高频有效FD映射，其内存占用与数据集大小无关；(2) 采用两阶段验证策略，先利用MHT缩小验证空间，再批量加载数据块验证剩余候选FD，减少重复I/O。

Result: 在真实数据集上的实验表明，EAIFD相比现有算法运行时间最多快一个数量级，内存使用减少两个数量级以上。

Conclusion: EAIFD是一种高效且可扩展的增量FD发现算法，在性能和内存效率方面显著优于现有方法，适用于大规模动态数据库环境。

Abstract: Functional dependencies (FDs) are fundamental integrity constraints in relational databases, but discovering them under incremental updates remains challenging. While static algorithms are inefficient due to full re-execution, incremental algorithms suffer from severe performance and memory bottlenecks. To address these challenges, this paper proposes EAIFD, a novel algorithm for incremental FD discovery. EAIFD maintains the partial hypergraph of difference sets and reframes the incremental FD discovery problem into minimal hitting set enumeration on hypergraph, avoiding full re-runs. EAIFD introduces two key innovations. First, a multi-attribute hash table ($MHT$) is devised for high-frequency key-value mappings of valid FDs, whose memory consumption is proven to be independent of the dataset size. Second, two-step validation strategy is developed to efficiently validate the enumerated candidates, which leverages $MHT$ to effectively reduce the validation space and then selectively loads data blocks for batch validation of remaining candidates, effectively avoiding repeated I/O operations. Experimental results on real-world datasets demonstrate the significant advantages of EAIFD. Compared to existing algorithms, EAIFD achieves up to an order-of-magnitude speedup in runtime while reducing memory usage by over two orders-of-magnitude, establishing it as a highly efficient and scalable solution for incremental FD discovery.

</details>
