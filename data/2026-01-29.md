<div id=toc></div>

# Table of Contents

- [Google Scholar](#Google Scholar) [Total: 1]
- [cs.DB](#cs.DB) [Total: 4]
- [learned "cost model"](#learned "cost model") [Total: 2]
- ["query optimization"](#"query optimization") [Total: 4]


<div id='Google Scholar'></div>

# Google Scholar [[Back]](#toc)

### [1] [High-Performance OLAP Across the Stack: From Algorithmic Data Reduction to Cloud-and GPU-Native Execution Engines](https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/3ad6647ba8c215ac85deef43b15f74f7/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=en&sa=X&d=13110096172478676035&ei=yd15adfrKp2J6rQP7NPO2AY&scisig=AHkA5jRfNl6sniM8N5gplRnviHTW&oi=scholaralrt&hist=Pxo5FIAAAAAJ:8045833917096571912:AHkA5jQiVAYaCDFgkLbBDuABZcUF&html=&pos=0&folt=cit)
*Y Yang*

Main category: Google Scholar

TL;DR: 该论文针对大规模SQL分析在现代数据系统中面临的性能挑战，提出了一系列横跨算法与系统架构的优化方法，重点减少中间数据量并提升在现代基础设施上的执行效率。


<details>
  <summary>Details</summary>
Motivation: 随着数据规模增长、连接模式复杂化以及云和硬件基础设施的演进，传统SQL分析系统在性能上面临严峻挑战，亟需从算法和系统层面进行协同优化。

Method: 论文提出了一套覆盖查询处理算法和系统执行架构的性能优化技术，特别聚焦于降低中间数据体积，并适配现代计算基础设施以提升执行效率。

Result: 通过所提出的优化方法，显著减少了中间数据量，并在现代基础设施上实现了更高效的SQL分析执行性能。

Conclusion: 结合算法与系统级的协同优化是提升大规模SQL分析性能的有效路径，尤其在应对现代数据规模和基础设施变化方面具有重要意义。

Abstract: Large-scale SQL analytics is a foundational component of modern data-driven systems, yet its performance is increasingly challenged by growing data volumes, complex join patterns, and evolving cloud and hardware infrastructures. Addressing these challenges requires innovations that span both algorithmic query processing and system-level execution architectures. This thesis presents a set of performance optimizations for large-scale SQL analytics across the algorithmic and infrastructure stacks, with a particular focus on reducing intermediate data volumes and improving execution efficiency on modern infrastructures.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [2] [Delta Fair Sharing: Performance Isolation for Multi-Tenant Storage Systems](https://arxiv.org/abs/2601.20030)
*Tyler Griggs,Soujanya Ponnapalli,Dev Bali,Wenjie Ma,James DeLoye,Audrey Cheng,Jaewan Hong,Natacha Crooks,Scott Shenker,Ion Stoica,Matei Zaharia*

Main category: cs.DB

TL;DR: 该论文提出Delta Fair Sharing算法，通过δ-公平性和δ-帕累托效率，在具有高抢占延迟的存储系统中实现性能隔离，有效限制尾延迟并提升资源利用率，并在RocksDB基础上实现了FAIRDB进行验证。


<details>
  <summary>Details</summary>
Motivation: 传统公平共享机制无法在云环境中为多租户存储系统提供有效的性能隔离，因为其资源（如写缓冲区和读缓存）存在高抢占延迟，导致客户端尾延迟不可控。

Method: 提出Delta Fair Sharing算法族，满足δ-公平性（保证客户端在δ时间内获得其应得资源份额）和δ-帕累托效率（将未使用资源分配给有未满足需求的客户端），并在RocksDB上实现为FAIRDB。

Result: 实验评估表明，FAIRDB相比现有最先进方法，能更有效地将行为良好的客户端与高需求工作负载隔离开，显著降低尾延迟尖峰。

Conclusion: Delta Fair Sharing通过端到端控制资源获取延迟，在保障性能隔离的同时维持高资源利用率，为多租户存储系统提供了实用且高效的公平调度方案。

Abstract: Modern storage systems, often deployed to support multiple tenants in the cloud, must provide performance isolation. Unfortunately, traditional approaches such as fair sharing do not provide performance isolation for storage systems, because their resources (e.g., write buffers and read caches) exhibit high preemption delays. These delays lead to unacceptable spikes in client tail latencies, as clients may be forced to wait arbitrarily long to receive their fair share of resources.
  We introduce Delta Fair Sharing, a family of algorithms for sharing resources with high preemption delays. These algorithms satisfy two key properties: $δ$-fairness, which bounds a client's delay in receiving its fair share of resources to $δ$ time units, and $δ$-Pareto-efficiency, which allocates unused resources to clients with unmet demand. Together, these properties capture resource-acquisition delays end-to-end, bound well-behaved clients' tail-latency spikes to $δ$ time units, and ensure high utilization. We implement such algorithms in FAIRDB, an extension of RocksDB. Our evaluation shows that FAIRDB isolates well-behaved clients from high-demand workloads better than state-of-the-art alternatives.

</details>


### [3] [ConStruM: A Structure-Guided LLM Framework for Context-Aware Schema Matching](https://arxiv.org/abs/2601.20482)
*Houming Chen,Zhe Zhang,H. V. Jagadish*

Main category: cs.DB

TL;DR: ConStruM is a structure-guided framework that improves schema column matching by selectively packing the most discriminative contextual evidence into LLM prompts under budget constraints.


<details>
  <summary>Details</summary>
Motivation: Existing LLM-based schema matching methods often lack sufficient contextual evidence beyond column names and descriptions, yet providing full schema metadata is impractical; thus, there is a need for an efficient method to select and organize the most useful contextual information for accurate matching.

Method: ConStruM constructs a lightweight, reusable structure comprising a context tree for multi-level budgeted retrieval and a global similarity hypergraph that identifies groups of highly similar columns. It generates query-specific context packs using group-aware differentiation cues (computed online or offline) and augments the LLM prompt of an upstream matcher’s candidate shortlist.

Result: Experiments on real datasets demonstrate that ConStruM effectively improves schema matching accuracy by delivering well-organized, discriminative contextual evidence within constrained input budgets.

Conclusion: ConStruM provides a practical, modular solution for enhancing LLM-based schema matching through intelligent, structure-guided evidence selection and organization, leading to better-grounded final decisions.

Abstract: Column matching is a central task in reconciling schemas for data integration. Column names and descriptions are valuable for this task. LLMs can leverage such natural-language schema metadata. However, in many datasets, correct matching requires additional evidence beyond the column itself. Because it is impractical to provide an LLM with the entire schema metadata needed to capture this evidence, the core challenge becomes to select and organize the most useful contextual information.
  We present ConStruM, a structure-guided framework for budgeted evidence packing in schema matching. ConStruM constructs a lightweight, reusable structure in which, at query time, it assembles a small context pack emphasizing the most discriminative evidence. ConStruM is designed as an add-on: given a shortlist of candidate targets produced by an upstream matcher, it augments the matcher's final LLM prompt with structured, query-specific evidence so that the final selection is better grounded. For this purpose, we develop a context tree for budgeted multi-level context retrieval and a global similarity hypergraph that surfaces groups of highly similar columns (on both the source and target sides), summarized via group-aware differentiation cues computed online or precomputed offline. Experiments on real datasets show that ConStruM improves matching by providing and organizing the right contextual evidence.

</details>


### [4] [ALER: An Active Learning Hybrid System for Efficient Entity Resolution](https://arxiv.org/abs/2601.20664)
*Dimitrios Karapiperis,Leonidas Akritidis,Panayiotis Bozanis,Vassilios Verykios*

Main category: cs.DB

TL;DR: ALER is a semi-supervised active learning pipeline for Entity Resolution that improves both computational efficiency and scalability by using a frozen bi-encoder, lightweight classifier, and a hybrid query strategy, achieving faster training and lower latency than existing methods.


<details>
  <summary>Details</summary>
Motivation: Supervised deep learning models for Entity Resolution require large labeled datasets, which are costly to obtain. Active Learning (AL) can reduce labeling needs but suffers from scalability issues due to expensive re-training or NP-hard selection problems in each iteration.

Method: ALER uses a frozen bi-encoder to generate static embeddings once, then iteratively trains a lightweight classifier. It addresses memory bottlenecks by sampling and clustering the data into semantically coherent chunks via K-Means. A hybrid query strategy selects both "confused" and "confident" pairs to refine the decision boundary and correct errors.

Result: On the DBLP dataset, ALER speeds up the training loop by 1.3× and reduces resolution latency by 3.8× compared to the fastest baseline, demonstrating superior efficiency and scalability.

Conclusion: ALER effectively bridges the gap between semantic accuracy and computational scalability in Entity Resolution, making active learning practical for large-scale real-world applications.

Abstract: Entity Resolution (ER) is a critical task for data integration, yet state-of-the-art supervised deep learning models remain impractical for many real-world applications due to their need for massive, expensive-to-obtain labeled datasets. While Active Learning (AL) offers a potential solution to this "label scarcity" problem, existing approaches introduce severe scalability bottlenecks. Specifically, they achieve high accuracy but incur prohibitive computational costs by re-training complex models from scratch or solving NP-hard selection problems in every iteration. In this paper, we propose ALER, a novel, semi-supervised pipeline designed to bridge the gap between semantic accuracy and computational scalability. ALER eliminates the training bottleneck by using a frozen bi-encoder architecture to generate static embeddings once and then iteratively training a lightweight classifier on top. To address the memory bottleneck associated with large-scale candidate pools, we first select a representative sample of the data and then use K-Means to partition this sample into semantically coherent chunks, enabling an efficient AL loop. We further propose a hybrid query strategy that combines "confused" and "confident" pairs to efficiently refine the decision boundary while correcting high-confidence errors.Extensive evaluation demonstrates ALER's superior efficiency, particularly on the large-scale DBLP dataset: it accelerates the training loop by 1.3x while drastically reducing resolution latency by a factor of 3.8 compared to the fastest baseline.

</details>


### [5] [The Monotone Priority System: Foundations of Contract-Specific Sequencing](https://arxiv.org/abs/2601.20783)
*Naveen Durvasula*

Main category: cs.DB

TL;DR: 该论文提出了一种基于整数优先级的智能合约调用排序机制，通过满足五个独立公理，确保了区块构建中交易排序的可表达性与可处理性之间的平衡。


<details>
  <summary>Details</summary>
Motivation: 现代区块链应用需要对交易执行顺序施加约束，但现有方法在表达能力和区块生成效率之间难以兼顾。作者旨在设计一种既具备足够表达力又便于区块构建的排序机制。

Method: 作者提出一种系统，允许合约开发者为每个函数调用设置一个整数全局优先级，前提是该优先级不高于其引用调用的优先级；区块构建者则按优先级从高到低排序交易，优先级相同时可自由决定顺序。

Result: 该系统被证明是唯一满足五个独立公理（包括一致性、局部性、单调性等）的排序机制，从而在理论上保证了其合理性与唯一性。

Conclusion: 所提出的基于优先级的排序机制在保持表达能力的同时确保了区块生产的可处理性，并通过公理化方法验证了其理论基础的坚实性。

Abstract: Modern blockchain applications benefit from the ability to specify sequencing constraints on the transactions that interact with them. This paper proposes a principled and axiomatically justified way of adding sequencing constraints on smart contract function calls that balances expressivity with the tractability of block production. Specifically, we propose a system in which contract developers are allowed to set an integer global priority for each of their calls, so long as that the call's chosen priority is no higher than the priority of any of its referenced calls. Block builders must then simply sequence transactions in priority order (from high to low priority), breaking ties however they would like. We show that this system is the unique system that satisfies five independent axioms.

</details>


<div id='learned "cost model"'></div>

# learned "cost model" [[Back]](#toc)

### [6] [[SoK] Systematizing Inference Placement For Deep Learning Across Edge And Cloud Platforms: A Multi-Objective Optimization Perspective](https://scholar.google.com/scholar_url?url=https://escholarship.org/content/qt23j1s4bg/qt23j1s4bg.pdf&hl=zh-CN&sa=X&d=4230595382320065700&ei=fot6aa3GOJ2J6rQP586poAg&scisig=AHkA5jQ_u7oimfQ3Ui_sjDYNJJMG&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=0&folt=kw-top)
*Z Zhang,I Matta*

Main category: learned "cost model"

TL;DR: 该综述探讨了在边缘智能应用中，如何通过模型卸载与模型自适应技术，在推理延迟、数据隐私和资源成本之间实现多目标优化。


<details>
  <summary>Details</summary>
Motivation: 随着VR/AR和基于大语言模型的聊天机器人等边缘智能应用的普及，受限的边缘设备难以承载日益庞大复杂的深度学习模型。现有研究需在用户设备、边缘服务器和云之间进行模型划分与卸载，以兼顾延迟、成本与隐私，但通信开销和数据泄露风险成为关键挑战。

Method: 文章系统综述了当前主流的模型卸载方法和模型自适应技术，包括模型压缩、知识蒸馏、传输压缩以及引入内部分类器等架构调整策略，并将其置于推理延迟、数据隐私和资源成本的多目标优化框架下进行分析。

Result: 综述表明，现有方法在多目标权衡方面取得进展，能够根据应用场景在延迟、隐私和成本之间进行灵活调整，但仍缺乏统一的评估标准和端到端的协同优化机制。

Conclusion: 未来研究应聚焦于构建更高效的联合优化框架，整合模型结构、卸载策略与安全机制，以实现边缘智能系统在性能、成本与隐私之间的最优平衡。

Abstract: Edge intelligent applications like VR/AR and language model based chatbots have become widespread with the rapid expansion of IoT and mobile devices. However, constrained edge devices often cannot serve the increasingly large and complex deep learning (DL) models. To mitigate these challenges, researchers have proposed optimizing and offloading partitions of DL models among user devices, edge servers, and the cloud. In this setting, users can take advantage of different services to support their intelligent applications. For example, edge resources offer low response latency. In contrast, cloud platforms provide low monetary cost computation resources for computation-intensive workloads. However, communication between DL model partitions can introduce transmission bottlenecks and pose risks of data leakage. Recent research aims to balance accuracy, computation delay, transmission delay, and privacy concerns. They address these issues with model compression, model distillation, transmission compression, and model architecture adaptations, including internal classifiers. This survey contextualizes the state-of-the-art model offloading methods and model adaptation techniques by studying their implication to a multi-objective optimization comprising inference latency, data privacy, and resource monetary cost.

</details>


### [7] [A Continuous Optimization Approach for Deadline-Constrained Cloud Workflow Scheduling](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11363206/&hl=zh-CN&sa=X&d=11188301759727069938&ei=fot6aa3GOJ2J6rQP586poAg&scisig=AHkA5jSBJqi0T02CBP5b5F3ZA9_W&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=2&folt=kw-top)
*L Yang,L Ye,Y Xia*

Main category: learned "cost model"

TL;DR: 本文提出一种连续优化方法SL-DMSPSO，通过动态多群粒子群优化与社会学习机制，有效解决云环境中截止时间约束的工作流调度问题。


<details>
  <summary>Details</summary>
Motivation: 现有工作流调度方法在处理截止时间约束时存在两大缺陷：一是采用固定的子截止时间分配策略，缺乏对不同工作流结构的适应性；二是基于离散编码的元启发式搜索效率低，需依赖复杂的修复规则。为克服这些限制，作者转向连续优化框架以更灵活高效地处理截止时间约束。

Method: 将每个任务的子截止时间视为连续决策变量，构建连续优化问题；设计Dynamic Multi-Swarm Particle Swarm Optimization with Social Learning (SL-DMSPSO)算法求解该问题，其核心创新包括：1）在每次迭代中动态随机重组多个粒子群，促进群体间信息交换并增强探索多样性；2）在粒子更新中融合个体学习与社会学习机制，平衡收敛性与多样性。

Result: 在真实工作流数据集上的实验表明，所提出的SL-DMSPSO算法在调度成功率、资源利用率等指标上优于当前最先进的对比算法，能更有效地满足截止时间约束。

Conclusion: 将截止时间约束工作流调度建模为连续优化问题并结合动态多群与社会学习的PSO变体，是一种高效且适应性强的解决方案，显著提升了云环境中QoS保障能力。

Abstract: In cloud computing, deadline-constrained workflow scheduling, a typical NP-hard problem, plays a vital role in meeting users’ quality-of-service (QoS) and efficiently managing cloud resources. Its core difficulty lies in handling the deadline constraint, where existing methods suffer from two major issues: fixed deadline distribution strategies, which lack adaptability to diverse workflows, and inefficient metaheuristic search, which requires discrete encodings and repair rules in the combinatorial space. To overcome these limitations, we propose a continuous optimization approach to efficiently address the deadline constraint. The basic idea is to find the suitable sub-deadline of each task by iterative optimization for each workflow. First, treating each task’s sub-deadline as a decision variable, a continuous optimization problem is established to solve deadline-constrained workflow scheduling. Then, a Dynamic Multi-Swarm Particle Swarm Optimization with Social Learning (SL-DMSPSO) algorithm is proposed for this continuous optimization problem, incorporating with the following two novel designs: 1) the entire population is divided into multiple swarms and is re-divided at each iteration, ensuring that swarms are dynamic and randomly assigned, which facilitates information exchange among swarms and enhances exploration diversity. 2) social learning is introduced when updating the particles in each swarm, combined with individual learning to balance diversity and convergence. Experiments are conducted on real-world workflows to compare SL-DMSPSO with state-of-the-art algorithms and the results reveal the superiority of SL-DMSPSO in effectively scheduling deadline-constrained workflows in clouds.

</details>


<div id='"query optimization"'></div>

# "query optimization" [[Back]](#toc)

### [8] [Push Down Optimization for Distributed Multi Cloud Data Integration](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Vinoth-Punniyamoorthy/publication/400035834_Push_Down_Optimization_for_Distributed_Multi_Cloud_Data_Integration/links/6973fbf558b9985baa8a8ad0/Push-Down-Optimization-for-Distributed-Multi-Cloud-Data-Integration.pdf&hl=zh-CN&sa=X&d=9015851721569140497&ei=fot6adn5MvDB6rQPpbu0gQw&scisig=AHkA5jQz7Y7HLlQg_wEWIxkFL5SJ&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=0&folt=kw-top)
*RK Kodali,V Punniyamoorthy,AK Agarwal,B Kumar…*

Main category: "query optimization"

TL;DR: 本文研究了在多云ETL（抽取、转换、加载）管道中应用下推优化的可行性，评估了本地化下推、混合模型和数据联邦等技术，以减少跨云数据传输并提升性能。通过Redshift与BigQuery的案例验证，展示了端到端运行时间缩短、传输量减少及成本效率提升等实际收益。


<details>
  <summary>Details</summary>
Motivation: 企业在多云架构中面临ETL管道的高延迟和高传输成本问题；虽然下推优化在单云环境中有效，但在多云环境下受制于数据移动、异构SQL引擎、编排复杂性和安全控制碎片化等挑战，亟需系统性评估其适用性与优化策略。

Method: 论文分析并比较了多种适用于多云环境的下推优化方法，包括本地化下推、混合执行模型和数据联邦技术，并通过在Amazon Redshift与Google BigQuery之间的实际案例进行实证评估。

Result: 实验结果表明，采用所提策略可显著降低端到端ETL运行时间、减少跨云数据传输量，并提升整体成本效益，验证了下推优化在多云ETL中的可行性和优势。

Conclusion: 在多云ETL环境中，合理应用下推优化及相关技术能有效提升性能、降低成本；企业可通过本地化处理、混合执行和数据联邦等实用策略增强ETL系统的可扩展性与可靠性。

Abstract: Enterprises increasingly adopt multi cloud architectures to take advantage of diverse database engines, regional availability, and cost models. In these environments, ETL pipelines must process large, distributed datasets while minimizing latency and transfer cost. Push down optimization, which executes transformation logic within database engines rather than within the ETL tool, has proven highly effective in single cloud systems. However, when applied across multiple clouds, it faces challenges related to data movement, heterogeneous SQL engines, orchestration complexity, and fragmented security controls. This paper examines the feasibility of push down optimization in multi cloud ETL pipelines and analyzes its benefits and limitations. It evaluates localized push down, hybrid models, and data federation techniques that reduce cross cloud traffic while improving performance. A case study across Redshift and BigQuery demonstrates measurable gains, including lower end to end runtime, reduced transfer volume, and improved cost efficiency. The study highlights practical strategies that organizations can adopt to improve ETL scalability and reliability in distributed cloud environments.

</details>


### [9] [A new relational division operation and its implementation](https://scholar.google.com/scholar_url?url=https://aaltodoc.aalto.fi/bitstreams/17119f3d-f634-4612-b7ef-eec95b859ba7/download&hl=zh-CN&sa=X&d=6583700010539202906&ei=fot6adn5MvDB6rQPpbu0gQw&scisig=AHkA5jS3E50Hu9xUkfxmD6tgSyWU&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=1&folt=kw-top)
*D Tlekbay*

Main category: "query optimization"

TL;DR: 该论文研究如何在SQL中有效表达全称量化（universal quantification），提出以关系除法（relational division）为基础，并发现分组广义除法（grouped generalized division）是最具表达力且与SQL兼容的方式。


<details>
  <summary>Details</summary>
Motivation: SQL缺乏直接表达“对所有”（FOR ALL）语义的机制，通常依赖嵌套否定、集合差或聚合操作，导致语义模糊和性能不一致。因此，需探索更清晰、高效的方式来实现全称量化查询。

Method: 以关系除法为代数基础，系统比较多种关系除法算子（标准除法、广义除法、小除/大除、分组广义除法），从语义、表达能力、可实现性、可重写性和计算复杂度等方面构建对比框架。

Result: 分组广义除法在表达受限和分组的全称查询方面最为有效，与SQL的分组和聚合特性自然契合，并能被现代查询优化器高效处理。

Conclusion: 关系除法仍是连接逻辑表达能力与实际查询优化的关键概念，在关系模型中具有持续的理论与实践价值。

Abstract: Universal quantification—that is, requirements which must be met by all related entities—is a foundational yet challenging concept for SQL to capture efficiently. Whereas such conditions are natural in logical formalisms (such as relational calculus), SQL offers no direct “FOR ALL” quantifier nor a relational division operator. Thus, universal queries are typically expressed through nested negation, set difference, or aggregation, which can obscure intent and lead to varying performance across database systems. This thesis uses relational division as the algebraic foundation for representing universal quantification and looks into how the classical and extended forms can be implemented effectively in SQL. This study contrasts several relational division operators, such as standard division, generalized division, the small and great divide, and the grouped generalized division. A comparative framework is developed for these operators in respect of semantics, expressiveness, realizability, rewriteability, and computational complexity. These results indicate that the grouped generalized division operator is the most expressive and SQL-compatible manner of expressing restricted and grouped universal queries. This naturally matches up with newer features in SQL such as grouping and aggregation. It enables efficient evaluation strategies supported by contemporary query optimizers. This results in the finding that relational division remains a central concept in bridging logical expressiveness and practical query optimization in the relational model.

</details>


### [10] [An Empirical Analysis of NLP-Based Databases for Inventory Management](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/abstract/document/11361542/&hl=zh-CN&sa=X&d=9385061991542472781&ei=fot6adn5MvDB6rQPpbu0gQw&scisig=AHkA5jSRiPC5BxfLkmMhRqRNEtWQ&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=4&folt=kw-top)
*N Cabanos,W Le,A Ghassemi*

Main category: "query optimization"

TL;DR: 本文提出并评估了一个融合自然语言处理（NLP）的模块化库存管理系统，通过语义解析和Transformer模型将自然语言查询转换为优化的SQL命令，在查询效率、需求预测准确性和库存优化方面显著优于传统系统。


<details>
  <summary>Details</summary>
Motivation: 传统库存管理系统难以有效处理非结构化数据，且缺乏及时的决策支持能力。为提升电商与供应链场景下的运营效率，作者探索将NLP技术集成到库存管理中，以改善人机交互和数据分析能力。

Method: 构建了一个结合NLP、机器学习与混合数据库架构的模块化框架；利用语义解析和Transformer模型将自然语言查询转化为增强的SQL指令，并在真实与合成数据集上进行性能评估。

Result: 实验结果显示，该系统在查询执行时间、需求预测准确率和库存优化方面均有显著提升；相比传统系统，在成本效益和响应速度上表现更优。

Conclusion: NLP驱动的库存管理系统能有效提升供应链运营中的数据交互效率与预测分析能力，具有实际应用潜力。

Abstract: This article presents an empirical study on the integration of natural language processing (NLP) into inventory management systems to improve operational efficiency within e-commerce and supply chain contexts. Traditional inventory systems often face limitations in handling unstructured data and providing timely decision support. To address these challenges, a modular framework incorporating NLP, machine learning, and a hybrid database architecture is proposed and evaluated. The system enables users to interact through natural language queries, which are translated into improved SQL commands using semantic parsing and Transformer models. Performance evaluation using real-world and synthetic datasets demonstrates significant improvements in query execution time, demand prediction accuracy, and inventory optimization. Comparative results indicate that the NLP-based system outperforms conventional systems in both cost-efficiency and responsiveness. The findings demonstrate the potential of NLP-based inventory systems to improve data interaction and predictive analytics across supply chain operations.

</details>


### [11] [iPDB--Optimizing SQL Queries with ML and LLM Predicates](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/2601.16432&hl=zh-CN&sa=X&d=8841939764722241224&ei=fot6adn5MvDB6rQPpbu0gQw&scisig=AHkA5jSt-8-f5X0PXqDpCgUknlg4&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=5&folt=kw-top)
*U Kumarasinghe,T Liu,C Liu,WG Aref*

Main category: "query optimization"

TL;DR: 本文提出了iPDB系统，通过扩展SQL语法支持在关系型数据库内直接调用大语言模型（LLM）和机器学习模型，实现语义投影、选择、连接和分组等操作，并引入新的关系预测算子与语义查询优化技术，显著提升语义SQL查询的执行效率。


<details>
  <summary>Details</summary>
Motivation: 传统SQL和关系型数据库难以高效支持需要调用大语言模型或机器学习模型的查询任务，导致复杂的数据迁移和工程开销。因此，亟需一种能将模型推理无缝集成到数据库内部的系统。

Method: 提出iPDB系统，扩展SQL语法以支持在查询中嵌入LLM和ML调用；设计新型的关系预测算子（relational predict operator）；开发语义查询优化技术，使语义操作（如语义投影、选择、连接、分组）可被高效执行。

Result: iPDB能够高效执行包含语义操作的SQL查询，在性能上优于当前最先进的方法。

Conclusion: 通过将LLM和ML推理能力深度集成到关系型数据库中，iPDB有效解决了传统系统在处理语义查询时的兼容性与效率问题，为未来数据库与AI融合提供了可行路径。

Abstract: Structured Query Language (SQL) has remained the standard query language for databases. SQL is highly optimized for processing structured data laid out in relations. Meanwhile, in the present application development landscape, it is highly desirable to utilize the power of learned models to perform complex tasks. Large language models (LLMs) have been shown to understand and extract information from unstructured textual data. However, SQL as a query language and accompanying relational database systems are either incompatible or inefficient for workloads that require leveraging learned models. This results in complex engineering and multiple data migration operations that move data between the data sources and the model inference platform. In this paper, we present iPDB, a relational system that supports in-database machine learning (ML) and large language model (LLM) inferencing using extended SQL syntax. In iPDB, LLMs and ML calls can function as semantic projects, as predicates to perform semantic selects and semantic joins, or for semantic grouping in group-by clauses. iPDB has a novel relational predict operator and semantic query optimizations that enable users to write and efficiently execute semantic SQL queries, outperforming the state-of-the-art.

</details>
