<div id=toc></div>

# Table of Contents

- [cs.DB](#cs.DB) [Total: 1]


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [1] [The Pneuma Project: Reifying Information Needs as Relational Schemas to Automate Discovery, Guide Preparation, and Align Data with Intent](https://arxiv.org/abs/2601.03618)
*Muhammad Imam Luthfi Balaka,Raul Castro Fernandez*

Main category: cs.DB

TL;DR: Pneuma-Seeker is an LLM-powered system that helps users iteratively refine vague or evolving information needs into structured, usable documents by combining context specialization, dynamic planning, and shared-state convergence.


<details>
  <summary>Details</summary>
Motivation: Data discovery and preparation are major bottlenecks when user intent is unclear or changing; existing tools struggle to support iterative, language-guided exploration and documentation of such intent.

Method: The system uses three core architectural components: (1) context specialization to offload subtasks from the LLM, (2) a conductor-style planner that dynamically assembles execution plans, and (3) a convergence mechanism based on shared state. It integrates retrieval-augmented generation (RAG), agentic frameworks, and structured data preparation techniques.

Result: Evaluated via LLM-based user simulations, Pneuma-Seeker effectively surfaces latent user intent, guides data discovery, and generates fit-for-purpose documents while also functioning as an emergent documentation layer that captures institutional knowledge.

Conclusion: Pneuma-Seeker demonstrates that combining structured data modeling with LLM-driven interaction can address challenges in ambiguous data workflows, improving both productivity and organizational memory.

Abstract: Data discovery and preparation remain persistent bottlenecks in the data management lifecycle, especially when user intent is vague, evolving, or difficult to operationalize. The Pneuma Project introduces Pneuma-Seeker, a system that helps users articulate and fulfill information needs through iterative interaction with a language model-powered platform. The system reifies the user's evolving information need as a relational data model and incrementally converges toward a usable document aligned with that intent. To achieve this, the system combines three architectural ideas: context specialization to reduce LLM burden across subtasks, a conductor-style planner to assemble dynamic execution plans, and a convergence mechanism based on shared state. The system integrates recent advances in retrieval-augmented generation (RAG), agentic frameworks, and structured data preparation to support semi-automatic, language-guided workflows. We evaluate the system through LLM-based user simulations and show that it helps surface latent intent, guide discovery, and produce fit-for-purpose documents. It also acts as an emergent documentation layer, capturing institutional knowledge and supporting organizational memory.

</details>
