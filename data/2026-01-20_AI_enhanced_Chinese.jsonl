{"id": "scholar_617472f93518b57c1d63434782fa15f4", "title": "Optimus: Deployable Query Optimization via Novel SQL Rewrites", "authors": ["R Lone"], "summary": "Learned database query optimizers typically optimize over a set of configurations, which limits the attainable plan space. Optimus expands the action space itself by mining novel execution plan rewrites and learns to select among these actions online. Optimus utilizes graph-based inductive matrix completion and a multilayer perceptron with the objective of minimizing latency. Crucially, the system is deployable by design: it requires no engine modifications and its rules include guard-checked compilation. On the extended JOB \u2026", "categories": ["\"query optimization\""], "pdf": "https://scholar.google.com/scholar_url?url=https://openreview.net/forum%3Fid%3DZVzYv7Qois&hl=zh-CN&sa=X&d=8376193066075901600&ei=6ZFuaenOO7ui6rQPrda9qQc&scisig=AHkA5jTLjnx1W_57zUcFKN3puylq&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=0&folt=kw-top", "abs": "https://scholar.google.com/scholar_url?url=https://openreview.net/forum%3Fid%3DZVzYv7Qois&hl=zh-CN&sa=X&d=8376193066075901600&ei=6ZFuaenOO7ui6rQPrda9qQc&scisig=AHkA5jTLjnx1W_57zUcFKN3puylq&oi=scholaralrt&hist=Pxo5FIAAAAAJ:10189913451943534390:AHkA5jTEDuZMpn0kzIrVKhRpZyjA&html=&pos=0&folt=kw-top", "comment": "From Google Scholar Alert | R Lone - 4th Deployable AI Workshop - openreview.net", "source": "Google Scholar", "url": "https://openreview.net/forum?id=ZVzYv7Qois", "scholar_enhanced": true, "AI": {"tldr": "Optimus enhances query optimization by expanding the action space with novel execution plan rewrites, using graph-based inductive matrix completion and a multilayer perceptron to minimize latency, all while being deployable without engine modifications.", "motivation": "Traditional learned query optimizers are constrained by a fixed set of configurations, limiting the potential plan space; Optimus addresses this by dynamically discovering and utilizing new execution plan rewrites.", "method": "Optimus employs graph-based inductive matrix completion and a multilayer perceptron to learn and select among newly mined execution plan rewrites, aiming to minimize query latency.", "result": "Optimus demonstrates improved performance on the extended JOB benchmark by effectively selecting low-latency execution plans from an expanded action space.", "conclusion": "By expanding the optimizer's action space with learnable, novel rewrites and ensuring deployability without engine changes, Optimus offers a practical and effective approach to query optimization."}}
{"id": "scholar_53715e49d6c98c7fe922d78e345f7377", "title": "Chiplet Marketplace", "authors": ["E Irabor", "M Musavi", "A Das", "S Abadal"], "summary": "\u2026 needs of the evolving and heterogeneous pool of Machine Learning (ML) models in the literature. In \u2026 SET [30] mapper tool, and a cost model was customized to evaluate the cost of architecture. \u2026 The mapper used in SCAR is also based on SET \u2026", "categories": ["learned \"cost model\""], "pdf": "https://scholar.google.com/scholar_url?url=https://chiplet-marketplace.com/library/article/exploring-the-potential-of-wireless-enabled-multi-chip-ai-accelerators&hl=zh-CN&sa=X&d=15905730971111581745&ei=6pFuadGBDbK16rQP872hoQc&scisig=AHkA5jSmEA-IqNXHZLGuwcPOmbJJ&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=2&folt=kw-top", "abs": "https://scholar.google.com/scholar_url?url=https://chiplet-marketplace.com/library/article/exploring-the-potential-of-wireless-enabled-multi-chip-ai-accelerators&hl=zh-CN&sa=X&d=15905730971111581745&ei=6pFuadGBDbK16rQP872hoQc&scisig=AHkA5jSmEA-IqNXHZLGuwcPOmbJJ&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=2&folt=kw-top", "comment": "From Google Scholar Alert | M Hutner, R Sethuram, B Vinnakota\u2026 - 2020 IEEE 38th VLSI \u2026, 2020 - computer.org", "source": "Google Scholar", "url": "https://www.computer.org/csdl/proceedings-article/vts/2020/09107636/1koLquQmynm", "scholar_enhanced": true, "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5f02\u6784\u6027\u9700\u6c42\u7684\u67b6\u6784\u8bc4\u4f30\u65b9\u6cd5\uff0c\u57fa\u4e8eSET\u6620\u5c04\u5de5\u5177\u5e76\u5b9a\u5236\u4e86\u6210\u672c\u6a21\u578b\u3002", "motivation": "\u5e94\u5bf9\u6587\u732e\u4e2d\u4e0d\u65ad\u6f14\u5316\u7684\u5f02\u6784\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9\u67b6\u6784\u8bbe\u8ba1\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u57fa\u4e8eSET\u7684\u6620\u5c04\u5668\uff08mapper\uff09\u5de5\u5177\uff0c\u5e76\u5b9a\u5236\u6210\u672c\u6a21\u578b\u4ee5\u8bc4\u4f30\u67b6\u6784\u5f00\u9500\u3002", "result": "\u5b9e\u73b0\u4e86\u5bf9\u4e0d\u540cML\u6a21\u578b\u5728\u76ee\u6807\u67b6\u6784\u4e0a\u90e8\u7f72\u6210\u672c\u7684\u6709\u6548\u8bc4\u4f30\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u652f\u6301\u9762\u5411\u5f02\u6784ML\u6a21\u578b\u7684\u67b6\u6784\u4f18\u5316\u4e0e\u9009\u62e9\u3002"}}
{"id": "scholar_2e9b34de6b5ae96558fb0cca498c53dd", "title": "GRANII: Selection and Ordering of Primitives in GRAph Neural Networks using Input Inspection", "authors": ["D Lenadora", "V Sathia", "G Gerogiannis", "S Yesil\u2026"], "summary": "Over the years, many frameworks and optimization techniques have been proposed to accelerate graph neural networks (GNNs). In contrast to the optimizations explored in these systems, we observe that different matrix re-associations of GNN computations lead to novel input-sensitive performance behavior. We leverage this observation to propose GRANII, a system that exposes different compositions of sparse and dense matrix primitives based on different matrix re-associations of GNN computations and selects the best among them based on input attributes. GRANII executes in two stages:(1) an offline compilation stage that enumerates all valid re-associations leading to different sparse-dense matrix compositions and uses inputoblivious pruning techniques to prune away clearly unprofitable candidates, and (2) an online runtime system that explores the remaining candidates and uses light-weight cost models to select the best re-association based on the input graph and the embedding sizes. On a wide range of configurations, GRANII achieves a geo-mean speedup of 1.56\u00d7 for inference and 1.4\u00d7 for training across multiple GNN models and systems. We also show GRANII\u2019s technique functions on diverse implementations and with techniques such as sampling.", "categories": ["learned \"cost model\""], "pdf": "https://scholar.google.com/scholar_url?url=https://iacoma.cs.uiuc.edu/iacoma-papers/cgo26.pdf&hl=zh-CN&sa=X&d=14789439206722274806&ei=6pFuadGBDbK16rQP872hoQc&scisig=AHkA5jQhTAP8TFaFo7sH4CZZPq-l&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=3&folt=kw-top", "abs": "https://scholar.google.com/scholar_url?url=https://iacoma.cs.uiuc.edu/iacoma-papers/cgo26.pdf&hl=zh-CN&sa=X&d=14789439206722274806&ei=6pFuadGBDbK16rQP872hoQc&scisig=AHkA5jQhTAP8TFaFo7sH4CZZPq-l&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=3&folt=kw-top", "comment": "From Google Scholar Alert | D Lenadora, V Sathia, G Gerogiannis, S Yesil\u2026 - iacoma.cs.uiuc.edu", "source": "Google Scholar", "url": "https://iacoma.cs.uiuc.edu/iacoma-papers/cgo26.pdf", "scholar_enhanced": true, "AI": {"tldr": "GRANII is a system that accelerates GNNs by exploring different matrix re-associations of computations, selecting the optimal sparse-dense matrix composition based on input characteristics, and achieving significant speedups in both inference and training.", "motivation": "Existing GNN acceleration frameworks overlook performance opportunities arising from different matrix re-associations of GNN computations, which exhibit input-sensitive behavior. The authors aim to exploit this observation to improve execution efficiency.", "method": "GRANII uses a two-stage approach: (1) an offline compilation stage that enumerates valid matrix re-associations and prunes unprofitable ones using input-oblivious techniques, and (2) an online runtime system that selects the best re-association using lightweight cost models based on input graph and embedding sizes.", "result": "GRANII achieves a geometric mean speedup of 1.56\u00d7 for inference and 1.4\u00d7 for training across various GNN models, systems, and configurations, and is compatible with diverse implementations and sampling techniques.", "conclusion": "Matrix re-association offers a promising direction for input-sensitive GNN acceleration, and GRANII effectively leverages this insight to outperform existing systems without requiring changes to underlying GNN models or frameworks."}}
{"id": "scholar_d587c5a89451b2c9e8cac6a3268ab894", "title": "Algorithm-Hardware Co-Design of AdderNet Based Accelerators for Edge Intelligences", "authors": ["Y Zhang"], "summary": "The rapid growth of wearable and edge devices has revolutionized the way we collect and analyze data, enabling real-time insights across various applications, from health monitoring to smart environment management. This dissertation addresses the challenges associated with efficient near and in-sensor processing, emphasizing the critical role of algorithm-hardware co-design in optimizing performance within resource-constrained environments. Through a comprehensive examination of existing methodologies, this research highlights the inefficiencies that arise when algorithms and hardware are developed in isolation. By proposing an integrated co-design framework, the study demonstrates how tailored algorithms can leverage specialized hardware architectures to significantly enhance processing efficiency, reduce energy consumption, and minimize latency.", "categories": ["learned \"cost model\""], "pdf": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/e98a830fca19cabb52ea92608e50c2f1/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=zh-CN&sa=X&d=9359701451023318854&ei=6pFuadGBDbK16rQP872hoQc&scisig=AHkA5jS8McOBXXsSAZQmxcsYAmhJ&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=5&folt=kw-top", "abs": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/e98a830fca19cabb52ea92608e50c2f1/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=zh-CN&sa=X&d=9359701451023318854&ei=6pFuadGBDbK16rQP872hoQc&scisig=AHkA5jS8McOBXXsSAZQmxcsYAmhJ&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=5&folt=kw-top", "comment": "From Google Scholar Alert | Y Zhang - 2025 - search.proquest.com", "source": "Google Scholar", "url": "https://search.proquest.com/openview/e98a830fca19cabb52ea92608e50c2f1/1?pq-origsite=gscholar&cbl=18750&diss=y", "scholar_enhanced": true, "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u8d44\u6e90\u53d7\u9650\u7684\u53ef\u7a7f\u6234\u4e0e\u8fb9\u7f18\u8bbe\u5907\u4e2d\u8fd1\u4f20\u611f\u5668\u548c\u4f20\u611f\u5668\u5185\u5904\u7406\u7684\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5f00\u53d1\u7b97\u6cd5\u4e0e\u786c\u4ef6\u65f6\u5f80\u5f80\u76f8\u4e92\u72ec\u7acb\uff0c\u5bfc\u81f4\u5728\u8d44\u6e90\u53d7\u9650\u7684\u53ef\u7a7f\u6234\u548c\u8fb9\u7f18\u8bbe\u5907\u4e2d\u5904\u7406\u6548\u7387\u4f4e\u4e0b\u3001\u80fd\u8017\u9ad8\u3001\u5ef6\u8fdf\u5927\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u96c6\u6210\u7684\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u4f7f\u5b9a\u5236\u5316\u7b97\u6cd5\u80fd\u591f\u5145\u5206\u5229\u7528\u4e13\u7528\u786c\u4ef6\u67b6\u6784\u3002", "result": "\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5904\u7406\u6548\u7387\uff0c\u964d\u4f4e\u4e86\u80fd\u8017\uff0c\u5e76\u51cf\u5c11\u4e86\u5ef6\u8fdf\u3002", "conclusion": "\u7b97\u6cd5\u4e0e\u786c\u4ef6\u7684\u534f\u540c\u8bbe\u8ba1\u5bf9\u4e8e\u4f18\u5316\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u8fd1\u4f20\u611f\u5668\u548c\u4f20\u611f\u5668\u5185\u5904\u7406\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "scholar_1065d010a5324cee47949d977414c1f9", "title": "Advanced Techniques for Hall Thruster Research and Development", "authors": ["P Thoreau"], "summary": "Hall thrusters are the most common form of electric propulsion on spacecraft currently in Earth orbit, they offer excellent efficiency, high thrust to power, and have relatively simple power processing units. They have seen significant development since their first commercial flight in 1972, however, methods for characterizing their operation for both development and flight have remained relatively consistent. Therefore, advanced techniques have been developed to more effectively, efficiently, and expeditiously characterize thruster operation. These methods have been advanced through four primary approaches.", "categories": ["learned \"cost model\""], "pdf": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/74c2087cd9103554c88e2786f10dd3c5/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=zh-CN&sa=X&d=13511889157824109156&ei=6pFuadGBDbK16rQP872hoQc&scisig=AHkA5jRWGUncZsHn2RHmPasitIDN&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=6&folt=kw-top", "abs": "https://scholar.google.com/scholar_url?url=https://search.proquest.com/openview/74c2087cd9103554c88e2786f10dd3c5/1%3Fpq-origsite%3Dgscholar%26cbl%3D18750%26diss%3Dy&hl=zh-CN&sa=X&d=13511889157824109156&ei=6pFuadGBDbK16rQP872hoQc&scisig=AHkA5jRWGUncZsHn2RHmPasitIDN&oi=scholaralrt&hist=Pxo5FIAAAAAJ:15658717702251462117:AHkA5jRs58Sh7gAGjO8tMulsiOso&html=&pos=6&folt=kw-top", "comment": "From Google Scholar Alert | P Thoreau - 2025 - search.proquest.com", "source": "Google Scholar", "url": "https://search.proquest.com/openview/74c2087cd9103554c88e2786f10dd3c5/1?pq-origsite=gscholar&cbl=18750&diss=y", "scholar_enhanced": true, "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u970d\u5c14\u63a8\u529b\u5668\u8fd0\u884c\u8868\u5f81\u7684\u56db\u79cd\u5148\u8fdb\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u5347\u5176\u5728\u7814\u53d1\u4e0e\u98de\u884c\u4efb\u52a1\u4e2d\u7684\u6d4b\u8bd5\u6548\u7387\u4e0e\u7cbe\u5ea6\u3002", "motivation": "\u5c3d\u7ba1\u970d\u5c14\u63a8\u529b\u5668\u81ea1972\u5e74\u9996\u6b21\u5546\u4e1a\u98de\u884c\u4ee5\u6765\u5df2\u53d6\u5f97\u663e\u8457\u53d1\u5c55\uff0c\u4f46\u5176\u8fd0\u884c\u8868\u5f81\u65b9\u6cd5\u4ecd\u76f8\u5bf9\u4f20\u7edf\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u3001\u5feb\u901f\u548c\u6709\u6548\u7684\u6280\u672f\u4ee5\u652f\u6301\u8fdb\u4e00\u6b65\u5f00\u53d1\u4e0e\u5728\u8f68\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u79cd\u4e3b\u8981\u7684\u5148\u8fdb\u8868\u5f81\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u970d\u5c14\u63a8\u529b\u5668\u8fd0\u884c\u72b6\u6001\u7684\u6d4b\u8bd5\u4e0e\u5206\u6790\u3002", "result": "\u8fd9\u4e9b\u65b0\u65b9\u6cd5\u80fd\u591f\u66f4\u6709\u6548\u5730\u3001\u9ad8\u6548\u5730\u548c\u8fc5\u901f\u5730\u5b8c\u6210\u5bf9\u970d\u5c14\u63a8\u529b\u5668\u8fd0\u884c\u7279\u6027\u7684\u8868\u5f81\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u56db\u79cd\u5148\u8fdb\u8868\u5f81\u9014\u5f84\uff0c\u53ef\u663e\u8457\u63d0\u5347\u970d\u5c14\u63a8\u529b\u5668\u5728\u7814\u53d1\u548c\u98de\u884c\u9636\u6bb5\u7684\u6027\u80fd\u8bc4\u4f30\u80fd\u529b\uff0c\u63a8\u52a8\u5176\u672a\u6765\u5e94\u7528\u4e0e\u53d1\u5c55\u3002"}}
